{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "southeast-medium",
   "metadata": {},
   "source": [
    "* Tutorial: https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Linear_Mixed_Effects_Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "local-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "dtype = tf.float64\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_insteval():\n",
    "    url = ('https://raw.github.com/vincentarelbundock/Rdatasets/master/csv/'\n",
    "         'lme4/InstEval.csv')\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(url)\n",
    "        f = download.content.decode().splitlines()\n",
    "\n",
    "    iterator = csv.reader(f)\n",
    "    columns = next(iterator)[1:]\n",
    "    x_train = np.array([row[1:] for row in iterator], dtype=np.int)\n",
    "    metadata = {'columns': columns}\n",
    "    return x_train, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, metadata = load_insteval()\n",
    "data = pd.DataFrame(data, columns=metadata['columns'])\n",
    "data = data.rename(columns={'s': 'students',\n",
    "                            'd': 'instructors',\n",
    "                            'dept': 'departments',\n",
    "                            'y': 'ratings'})\n",
    "data['students'] -= 1  # start index by 0\n",
    "# Remap categories to start from 0 and end at max(category).\n",
    "data['instructors'] = data['instructors'].astype('category').cat.codes\n",
    "data['departments'] = data['departments'].astype('category').cat.codes\n",
    "\n",
    "train = data.sample(frac=0.8)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_value = lambda dataframe, key, dtype: dataframe[key].values.astype(dtype)\n",
    "features_train = {\n",
    "    k: get_value(train, key=k, dtype=np.int32)\n",
    "    for k in ['students', 'instructors', 'departments', 'service']}\n",
    "labels_train = get_value(train, key='ratings', dtype=np.float32)\n",
    "\n",
    "features_test = {k: get_value(test, key=k, dtype=np.int32)\n",
    "                 for k in ['students', 'instructors', 'departments', 'service']}\n",
    "labels_test = get_value(test, key='ratings', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_students = max(features_train['students']) + 1\n",
    "num_instructors = max(features_train['instructors']) + 1\n",
    "num_departments = max(features_train['departments']) + 1\n",
    "num_observations = train.shape[0]\n",
    "\n",
    "print(\"Number of students:\", num_students)\n",
    "print(\"Number of instructors:\", num_instructors)\n",
    "print(\"Number of departments:\", num_departments)\n",
    "print(\"Number of observations:\", num_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMixedEffectModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        # Set up fixed effects and other parameters.\n",
    "        # These are free parameters to be optimized in E-steps\n",
    "        self._intercept = tf.Variable(0., name=\"intercept\")            # alpha in eq\n",
    "        self._effect_service = tf.Variable(0., name=\"effect_service\")  #  beta in eq\n",
    "        self._stddev_students = tfp.util.TransformedVariable(\n",
    "            1., bijector=tfb.Exp(), name=\"stddev_students\")            # sigma in eq\n",
    "        self._stddev_instructors = tfp.util.TransformedVariable(\n",
    "            1., bijector=tfb.Exp(), name=\"stddev_instructors\")         # sigma in eq\n",
    "        self._stddev_departments = tfp.util.TransformedVariable(\n",
    "            1., bijector=tfb.Exp(), name=\"stddev_departments\")         # sigma in eq\n",
    "\n",
    "    def __call__(self, features):\n",
    "        model = tfd.JointDistributionSequential([\n",
    "          # Set up random effects.\n",
    "          tfd.MultivariateNormalDiag(\n",
    "              loc=tf.zeros(num_students),\n",
    "              scale_identity_multiplier=self._stddev_students),\n",
    "          tfd.MultivariateNormalDiag(\n",
    "              loc=tf.zeros(num_instructors),\n",
    "              scale_identity_multiplier=self._stddev_instructors),\n",
    "          tfd.MultivariateNormalDiag(\n",
    "              loc=tf.zeros(num_departments),\n",
    "              scale_identity_multiplier=self._stddev_departments),\n",
    "          # This is the likelihood for the observed.\n",
    "          lambda effect_departments, effect_instructors, effect_students: tfd.Independent(\n",
    "              tfd.Normal(\n",
    "                  loc=(self._effect_service * features[\"service\"] +\n",
    "                      tf.gather(effect_students, features[\"students\"], axis=-1) +\n",
    "                      tf.gather(effect_instructors, features[\"instructors\"], axis=-1) +\n",
    "                      tf.gather(effect_departments, features[\"departments\"], axis=-1) +\n",
    "                      self._intercept),\n",
    "                  scale=1.),\n",
    "                  reinterpreted_batch_ndims=1)\n",
    "        ])\n",
    "\n",
    "        # To enable tracking of the trainable variables via the created distribution,\n",
    "        # we attach a reference to `self`. Since all TFP objects sub-class\n",
    "        # `tf.Module`, this means that the following is possible:\n",
    "        # LinearMixedEffectModel()(features_train).trainable_variables\n",
    "        # ==> tuple of all tf.Variables created by LinearMixedEffectModel.\n",
    "        model._to_track = self\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmm_jointdist = LinearMixedEffectModel()\n",
    "# Conditioned on feature/predictors from the training data\n",
    "lmm_train = lmm_jointdist(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmm_train.trainable_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmm_train.resolve_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_log_prob_fn = lambda *x: lmm_train.log_prob(x + (labels_train,))\n",
    "trainable_variables = lmm_train.trainable_variables\n",
    "current_state = lmm_train.sample()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=target_log_prob_fn,\n",
    "    step_size=0.015,\n",
    "    num_leapfrog_steps=3)\n",
    "kernel_results = hmc.bootstrap_results(current_state)\n",
    "\n",
    "@tf.function(autograph=False, experimental_compile=True)\n",
    "def one_e_step(current_state, kernel_results):\n",
    "    next_state, next_kernel_results = hmc.one_step(\n",
    "      current_state=current_state,\n",
    "      previous_kernel_results=kernel_results)\n",
    "    return next_state, next_kernel_results\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=.01)\n",
    "\n",
    "# Set up M-step (gradient descent).\n",
    "@tf.function(autograph=False, experimental_compile=True)\n",
    "def one_m_step(current_state):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = -target_log_prob_fn(*current_state)\n",
    "    grads = tape.gradient(loss, trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_warmup_iters = 1000\n",
    "num_iters = 1500\n",
    "num_accepted = 0\n",
    "effect_students_samples = np.zeros([num_iters, num_students])\n",
    "effect_instructors_samples = np.zeros([num_iters, num_instructors])\n",
    "effect_departments_samples = np.zeros([num_iters, num_departments])\n",
    "loss_history = np.zeros([num_iters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(num_warmup_iters):\n",
    "  current_state, kernel_results = one_e_step(current_state, kernel_results)\n",
    "  num_accepted += kernel_results.is_accepted.numpy()\n",
    "  if t % 500 == 0 or t == num_warmup_iters - 1:\n",
    "    print(\"Warm-Up Iteration: {:>3} Acceptance Rate: {:.3f}\".format(\n",
    "        t, num_accepted / (t + 1)))\n",
    "\n",
    "num_accepted = 0  # reset acceptance rate counter\n",
    "\n",
    "# Run training.\n",
    "for t in range(num_iters):\n",
    "  # run 5 MCMC iterations before every joint EM update\n",
    "  for _ in range(5):\n",
    "    current_state, kernel_results = one_e_step(current_state, kernel_results)\n",
    "  loss = one_m_step(current_state)\n",
    "  effect_students_samples[t, :] = current_state[0].numpy()\n",
    "  effect_instructors_samples[t, :] = current_state[1].numpy()\n",
    "  effect_departments_samples[t, :] = current_state[2].numpy()\n",
    "  num_accepted += kernel_results.is_accepted.numpy()\n",
    "  loss_history[t] = loss.numpy()\n",
    "  if t % 500 == 0 or t == num_iters - 1:\n",
    "    print(\"Iteration: {:>4} Acceptance Rate: {:.3f} Loss: {:.3f}\".format(\n",
    "        t, num_accepted / (t + 1), loss_history[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.ylabel(r'Loss $-\\log$ $p(y\\mid\\mathbf{x})$')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "  plt.plot(effect_instructors_samples[:, i])\n",
    "\n",
    "plt.legend([i for i in range(7)], loc='lower right')\n",
    "plt.ylabel('Instructor Effects')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-sally",
   "metadata": {},
   "source": [
    "# Statsmodels\n",
    "* https://www.kaggle.com/ojwatson/mixed-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stunning-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "senior-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Mixed Linear Model Regression Results\n",
      "===========================================================\n",
      "Model:             MixedLM  Dependent Variable:  Weight    \n",
      "No. Observations:  861      Method:              REML      \n",
      "No. Groups:        72       Scale:               6.0372    \n",
      "Min. group size:   11       Log-Likelihood:      -2217.0475\n",
      "Max. group size:   12       Converged:           Yes       \n",
      "Mean group size:   12.0                                    \n",
      "-----------------------------------------------------------\n",
      "                 Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-----------------------------------------------------------\n",
      "Intercept        15.739    0.550 28.603 0.000 14.660 16.817\n",
      "Time              6.939    0.080 86.925 0.000  6.783  7.095\n",
      "Group Var        19.503    1.561                           \n",
      "Group x Time Cov  0.294    0.153                           \n",
      "Time Var          0.416    0.033                           \n",
      "===========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Formula indicates mean weight as a linear function of time. Random intercept for each pig. \n",
    "data = sm.datasets.get_rdataset('dietox', 'geepack').data\n",
    "md = smf.mixedlm(\"Weight ~ Time\", data, groups=data[\"Pig\"], re_formula=\"~Time\")\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "designed-tonight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       21.957902\n",
       "1       28.806111\n",
       "2       35.654320\n",
       "3       42.502529\n",
       "4       49.350737\n",
       "          ...    \n",
       "856     72.989071\n",
       "857     80.435264\n",
       "858     87.881457\n",
       "859     95.327649\n",
       "860    102.773842\n",
       "Length: 861, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = mdf.fittedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-sword",
   "metadata": {},
   "source": [
    "# Stats models on the FQI part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "official-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_tuples.json', 'r') as f:\n",
    "    train_dict = json.load(f)\n",
    "with open('test_tuples.json', 'r') as f:\n",
    "    test_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "immediate-bernard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a0', 'a1', 'r', 'ds', 's0', 's1', 's2', 's3', 's4', 's5', 's6', 's7',\n",
       "       's8', 's9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame.from_dict(train_dict)\n",
    "test_df = pd.DataFrame.from_dict(test_dict)\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "lined-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['r']\n",
    "X = train_df[['a0', 'a1', 's0', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9']]\n",
    "groups = train_df['ds']s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "vietnamese-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryamandyam/anaconda3/envs/tf/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/aishwaryamandyam/anaconda3/envs/tf/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2202: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  ConvergenceWarning)\n",
      "/Users/aishwaryamandyam/anaconda3/envs/tf/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/aishwaryamandyam/anaconda3/envs/tf/lib/python3.7/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = sm.MixedLM(endog=y, exog=X, groups=groups)\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "harmful-wilson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4.421987\n",
       "1        9.033591\n",
       "2       26.392287\n",
       "3       28.386333\n",
       "4       35.480719\n",
       "          ...    \n",
       "1995    31.096184\n",
       "1996    14.359744\n",
       "1997    21.499843\n",
       "1998     6.120035\n",
       "1999    15.712445\n",
       "Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX = test_df[['a0', 'a1', 's0', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9']]\n",
    "result.predict(exog=testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-calculator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
