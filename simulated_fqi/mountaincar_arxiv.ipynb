{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configargparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environments import MountainCarEnv, Continuous_MountainCarEnv\n",
    "from models.agents import NFQAgent\n",
    "from models.networks import NFQNetwork, ContrastiveNFQNetwork\n",
    "from util import get_logger, close_logger, load_models, make_reproducible, save_models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = MountainCarEnv()\n",
    "car.reset()\n",
    "n_iter = 2000\n",
    "\n",
    "rewards = []\n",
    "for ii in range(1, n_iter):\n",
    "\n",
    "    # Randomly sample an action\n",
    "    a = car.action_space.sample()\n",
    "\n",
    "    # Perform the action\n",
    "    s, reward, _, _ = car.step(a)\n",
    "\n",
    "    # Render the current frame\n",
    "    rewards.append(reward)\n",
    "    #car.render()\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "sns.distplot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = Continuous_MountainCarEnv(group=0)\n",
    "car.reset()\n",
    "n_iter = 2000\n",
    "\n",
    "rewards = []\n",
    "for ii in range(1, n_iter):\n",
    "\n",
    "    # Randomly sample an action\n",
    "    a = car.action_space.sample()\n",
    "\n",
    "    # Perform the action\n",
    "    s, reward, _, _ = car.step(a)\n",
    "\n",
    "    # Render the current frame\n",
    "    rewards.append(reward)\n",
    "    car.reset()\n",
    "    #car.render()\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "sns.distplot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = Continuous_MountainCarEnv(group=1)\n",
    "car.reset()\n",
    "n_iter = 2000\n",
    "\n",
    "rewards = []\n",
    "for ii in range(1, n_iter):\n",
    "\n",
    "    # Randomly sample an action\n",
    "    a = car.action_space.sample()\n",
    "\n",
    "    # Perform the action\n",
    "    s, reward, _, _ = car.step(a)\n",
    "\n",
    "    # Render the current frame\n",
    "    rewards.append(reward)\n",
    "    car.reset()\n",
    "    #car.render()\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "sns.distplot(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement FQI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(init_experience=400):\n",
    "    env_bg = Continuous_MountainCarEnv(group=0)\n",
    "    env_fg = Continuous_MountainCarEnv(group=1)\n",
    "    bg_rollouts = []\n",
    "    fg_rollouts = []\n",
    "    if init_experience > 0:\n",
    "        for _ in range(init_experience):\n",
    "            rollout_bg, episode_cost = env_bg.generate_rollout(\n",
    "                None, render=False, group=0\n",
    "            )\n",
    "            rollout_fg, episode_cost = env_fg.generate_rollout(\n",
    "                None, render=False, group=1\n",
    "            )\n",
    "            bg_rollouts.extend(rollout_bg)\n",
    "            fg_rollouts.extend(rollout_fg)\n",
    "    bg_rollouts.extend(fg_rollouts)\n",
    "    all_rollouts = bg_rollouts.copy()\n",
    "    return all_rollouts, env_bg, env_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 7/401 [00:07<07:29,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 True 99.9\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "0 False -9.99999999999998\n",
      "0 False -9.99999999999998\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "0 False -9.99999999999998\n",
      "0 False -9.99999999999998\n",
      "0 False -9.99999999999998\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "0 False -9.99999999999998\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "1 True 99.9\n",
      "Fg trained after 0 epochs\n",
      "BG stayed up for steps:  [1, 1, 0, 1, 0, 0, 1, 1, 1, 1]\n",
      "FG stayed up for steps:  [1, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "is_contrastive=False\n",
    "epoch = 400\n",
    "evaluations = 10\n",
    "verbose=True\n",
    "print(\"Generating Data\")\n",
    "train_rollouts, train_env_bg, train_env_fg = generate_data()\n",
    "test_rollouts, eval_env_bg, eval_env_fg = generate_data()\n",
    "\n",
    "nfq_net = ContrastiveNFQNetwork(\n",
    "    state_dim=train_env_bg.state_dim, is_contrastive=is_contrastive\n",
    ")\n",
    "optimizer = optim.Adam(nfq_net.parameters(), lr=1e-1)\n",
    "\n",
    "nfq_agent = NFQAgent(nfq_net, optimizer)\n",
    "\n",
    "# NFQ Main loop\n",
    "bg_success_queue = [0] * 3\n",
    "fg_success_queue = [0] * 3\n",
    "epochs_fg = 0\n",
    "eval_fg = 0\n",
    "for k, epoch in enumerate(tqdm.tqdm(range(epoch + 1))):\n",
    "    state_action_b, target_q_values, groups = nfq_agent.generate_pattern_set(\n",
    "        train_rollouts\n",
    "    )\n",
    "    X = state_action_b\n",
    "    train_groups = groups\n",
    "\n",
    "    if not nfq_net.freeze_shared:\n",
    "        loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    eval_episode_length_fg, eval_success_fg, eval_episode_cost_fg = 0, 0, 0\n",
    "    if nfq_net.freeze_shared:\n",
    "        eval_fg += 1\n",
    "\n",
    "        if eval_fg > 50:\n",
    "            loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    (eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg) = nfq_agent.evaluate_car(eval_env_bg, render=False)\n",
    "    (eval_episode_length_fg,eval_success_fg, eval_episode_cost_fg) = nfq_agent.evaluate_car(eval_env_fg, render=False)\n",
    "\n",
    "    bg_success_queue = bg_success_queue[1:]\n",
    "    bg_success_queue.append(1 if eval_success_bg else 0)\n",
    "\n",
    "    fg_success_queue = fg_success_queue[1:]\n",
    "    fg_success_queue.append(1 if eval_success_fg else 0)\n",
    "\n",
    "    printed_bg = False\n",
    "    printed_fg = False\n",
    "\n",
    "    if sum(bg_success_queue) == 3 and not nfq_net.freeze_shared == True:\n",
    "        if epochs_fg == 0:\n",
    "            epochs_fg = epoch\n",
    "        printed_bg = True\n",
    "        nfq_net.freeze_shared = True\n",
    "        if verbose:\n",
    "            print(\"FREEZING SHARED\")\n",
    "        if is_contrastive:\n",
    "            for param in nfq_net.layers_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            optimizer = optim.Adam(\n",
    "                itertools.chain(\n",
    "                    nfq_net.layers_fg.parameters(),\n",
    "                    nfq_net.layers_last_fg.parameters(),\n",
    "                ),\n",
    "                lr=1e-1,\n",
    "            )\n",
    "            nfq_agent._optimizer = optimizer\n",
    "\n",
    "    # Print current status\n",
    "#     if verbose:\n",
    "#         logger.info(\n",
    "#             \"Epoch {:4d} | Eval BG {:4d} / {:4f} | Eval FG {:4d} / {:4f} | Train Loss {:.4f}\".format(\n",
    "#                 epoch,\n",
    "#                 eval_episode_length_bg,\n",
    "#                 eval_episode_cost_bg,\n",
    "#                 eval_episode_length_fg,\n",
    "#                 eval_episode_cost_fg,\n",
    "#                 loss,\n",
    "#             )\n",
    "#         )\n",
    "    if sum(fg_success_queue) == 3:\n",
    "        printed_fg = True\n",
    "#         if verbose:\n",
    "#             logger.info(\n",
    "#                 \"Epoch {:4d} | Total Cycles {:6d} | Total Cost {:4.2f}\".format(\n",
    "#                     epoch, len(all_rollouts), total_cost\n",
    "#                 )\n",
    "#             )\n",
    "        break\n",
    "\n",
    "eval_env_bg.step_number = 0\n",
    "eval_env_fg.step_number = 0\n",
    "\n",
    "eval_env_bg.max_steps = 1000\n",
    "eval_env_fg.max_steps = 1000\n",
    "\n",
    "performance_fg = []\n",
    "performance_bg = []\n",
    "num_steps_bg = []\n",
    "num_steps_fg = []\n",
    "total = 0\n",
    "for it in range(evaluations):\n",
    "    (\n",
    "        eval_episode_length_bg,\n",
    "        eval_success_bg,\n",
    "        eval_episode_cost_bg,\n",
    "    ) = nfq_agent.evaluate_car(eval_env_bg, False)\n",
    "    if verbose:\n",
    "        print(eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg)\n",
    "    num_steps_bg.append(eval_episode_length_bg)\n",
    "    performance_bg.append(eval_episode_length_bg)\n",
    "    total += 1\n",
    "    train_env_bg.close()\n",
    "    eval_env_bg.close()\n",
    "\n",
    "    (\n",
    "        eval_episode_length_fg,\n",
    "        eval_success_fg,\n",
    "        eval_episode_cost_fg,\n",
    "    ) = nfq_agent.evaluate_car(eval_env_fg, False)\n",
    "    if verbose:\n",
    "        print(eval_episode_length_fg, eval_success_fg, eval_episode_cost_fg)\n",
    "    num_steps_fg.append(eval_episode_length_fg)\n",
    "    performance_fg.append(eval_episode_length_fg)\n",
    "    total += 1\n",
    "    train_env_fg.close()\n",
    "    eval_env_fg.close()\n",
    "print(\"Fg trained after \" + str(epochs_fg) + \" epochs\")\n",
    "print(\"BG stayed up for steps: \", num_steps_bg)\n",
    "print(\"FG stayed up for steps: \", num_steps_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research [~/.conda/envs/research/]",
   "language": "python",
   "name": "conda_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
