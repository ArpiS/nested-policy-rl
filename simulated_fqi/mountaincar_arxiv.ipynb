{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval can start anywhere from left to goal state, vel 0 (also training). They need 71 episodes\n",
    "# Modify cartpole to only have two actions-> left and right. The magnitude of the actions are much larger in nfq paper\n",
    "# Need to do hint to goal\n",
    "# Do this on pendulum too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configargparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from environments import MountainCarEnv, Continuous_MountainCarEnv\n",
    "from models.agents import NFQAgent\n",
    "from models.networks import NFQNetwork, ContrastiveNFQNetwork\n",
    "from util import get_logger, close_logger, load_models, make_reproducible, save_models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(init_experience=100, bg_only=False, continuous=False, agent=None, dataset='train'):\n",
    "    if continuous:\n",
    "        env_bg = Continuous_MountainCarEnv(group=0)\n",
    "        env_fg = Continuous_MountainCarEnv(group=1)\n",
    "    else:\n",
    "        env_bg = MountainCarEnv(group=0)\n",
    "        env_fg = MountainCarEnv(group=1)\n",
    "    bg_rollouts = []\n",
    "    fg_rollouts = []\n",
    "    if init_experience > 0:\n",
    "        for _ in range(init_experience):\n",
    "            rollout_bg, episode_cost = env_bg.generate_rollout(\n",
    "                agent, render=False, group=0, dataset=dataset\n",
    "            )\n",
    "            bg_rollouts.extend(rollout_bg)\n",
    "            if not bg_only:\n",
    "                rollout_fg, episode_cost = env_fg.generate_rollout(\n",
    "                    agent, render=False, group=1, dataset=dataset\n",
    "                )\n",
    "                fg_rollouts.extend(rollout_fg)\n",
    "    bg_rollouts.extend(fg_rollouts)\n",
    "    all_rollouts = bg_rollouts.copy()\n",
    "    return all_rollouts, env_bg, env_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_bg = MountainCarEnv(group=0)\n",
    "env_bg.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Mountaincar\n",
    "* There are quite a few actions. This makes it hard for FQI to learn to succeed on this task. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "is_contrastive=False\n",
    "epoch = 400\n",
    "evaluations = 10\n",
    "verbose=True\n",
    "print(\"Generating Data\")\n",
    "train_rollouts, train_env_bg, train_env_fg = generate_data()\n",
    "test_rollouts, eval_env_bg, eval_env_fg = generate_data()\n",
    "\n",
    "nfq_net = ContrastiveNFQNetwork(\n",
    "    state_dim=train_env_bg.state_dim, is_contrastive=is_contrastive\n",
    ")\n",
    "optimizer = optim.Adam(nfq_net.parameters(), lr=1e-1)\n",
    "\n",
    "nfq_agent = NFQAgent(nfq_net, optimizer)\n",
    "\n",
    "# NFQ Main loop\n",
    "bg_success_queue = [0] * 3\n",
    "fg_success_queue = [0] * 3\n",
    "epochs_fg = 0\n",
    "eval_fg = 0\n",
    "for k, epoch in enumerate(tqdm.tqdm(range(epoch + 1))):\n",
    "    state_action_b, target_q_values, groups = nfq_agent.generate_pattern_set(\n",
    "        train_rollouts\n",
    "    )\n",
    "    X = state_action_b\n",
    "    train_groups = groups\n",
    "\n",
    "    if not nfq_net.freeze_shared:\n",
    "        loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    eval_episode_length_fg, eval_success_fg, eval_episode_cost_fg = 0, 0, 0\n",
    "    if nfq_net.freeze_shared:\n",
    "        eval_fg += 1\n",
    "\n",
    "        if eval_fg > 50:\n",
    "            loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    (eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg) = nfq_agent.evaluate_car(eval_env_bg, render=False)\n",
    "    (eval_episode_length_fg,eval_success_fg, eval_episode_cost_fg) = nfq_agent.evaluate_car(eval_env_fg, render=False)\n",
    "\n",
    "    bg_success_queue = bg_success_queue[1:]\n",
    "    bg_success_queue.append(1 if eval_success_bg else 0)\n",
    "\n",
    "    fg_success_queue = fg_success_queue[1:]\n",
    "    fg_success_queue.append(1 if eval_success_fg else 0)\n",
    "\n",
    "    printed_bg = False\n",
    "    printed_fg = False\n",
    "\n",
    "    if sum(bg_success_queue) == 3 and not nfq_net.freeze_shared == True:\n",
    "        if epochs_fg == 0:\n",
    "            epochs_fg = epoch\n",
    "        printed_bg = True\n",
    "        nfq_net.freeze_shared = True\n",
    "        if verbose:\n",
    "            print(\"FREEZING SHARED\")\n",
    "        if is_contrastive:\n",
    "            for param in nfq_net.layers_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            optimizer = optim.Adam(\n",
    "                itertools.chain(\n",
    "                    nfq_net.layers_fg.parameters(),\n",
    "                    nfq_net.layers_last_fg.parameters(),\n",
    "                ),\n",
    "                lr=1e-1,\n",
    "            )\n",
    "            nfq_agent._optimizer = optimizer\n",
    "\n",
    "    if sum(fg_success_queue) == 3:\n",
    "        printed_fg = True\n",
    "        break\n",
    "\n",
    "eval_env_bg.step_number = 0\n",
    "eval_env_fg.step_number = 0\n",
    "\n",
    "eval_env_bg.max_steps = 1000\n",
    "eval_env_fg.max_steps = 1000\n",
    "\n",
    "performance_fg = []\n",
    "performance_bg = []\n",
    "num_steps_bg = []\n",
    "num_steps_fg = []\n",
    "total = 0\n",
    "for it in range(evaluations):\n",
    "    (\n",
    "        eval_episode_length_bg,\n",
    "        eval_success_bg,\n",
    "        eval_episode_cost_bg,\n",
    "    ) = nfq_agent.evaluate_car(eval_env_bg, False)\n",
    "    if verbose:\n",
    "        print(eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg)\n",
    "    num_steps_bg.append(eval_episode_length_bg)\n",
    "    performance_bg.append(eval_episode_length_bg)\n",
    "    total += 1\n",
    "    train_env_bg.close()\n",
    "    eval_env_bg.close()\n",
    "\n",
    "    (\n",
    "        eval_episode_length_fg,\n",
    "        eval_success_fg,\n",
    "        eval_episode_cost_fg,\n",
    "    ) = nfq_agent.evaluate_car(eval_env_fg, False)\n",
    "    if verbose:\n",
    "        print(eval_episode_length_fg, eval_success_fg, eval_episode_cost_fg)\n",
    "    num_steps_fg.append(eval_episode_length_fg)\n",
    "    performance_fg.append(eval_episode_length_fg)\n",
    "    total += 1\n",
    "    train_env_fg.close()\n",
    "    eval_env_fg.close()\n",
    "print(\"Fg trained after \" + str(epochs_fg) + \" epochs\")\n",
    "print(\"BG stayed up for steps: \", num_steps_bg)\n",
    "print(\"FG stayed up for steps: \", num_steps_fg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Mountaincar\n",
    "* Has three actions, easier for FQI to understand what's going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using random actions to generate rollout results in the agent never succeeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amandyam/.conda/envs/research/lib/python3.6/site-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_rollouts, train_env_bg, train_env_fg = generate_data(bg_only=True, continuous=False)\n",
    "rewards = [r[2] for r in train_rollouts]\n",
    "actions = [r[1] for r in train_rollouts]\n",
    "sns.distplot(rewards, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a model to generate actions that are better than random\n",
    "* This doesn't do well either without any adjustments. The model can't really learn how to make it past -0.4 position\n",
    "* Even if we change the reward to be continuous, FQI can't learn it.\n",
    "* However, we can make the reset speed 0.3, we sometimes learn it. \n",
    "* When we train a model, the reset has a speed of 0. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "is_contrastive=False\n",
    "epoch = 100\n",
    "\n",
    "train_rollouts, train_env_bg, train_env_fg = generate_data(bg_only=True, continuous=False, dataset='train')\n",
    "test_rollouts, eval_env_bg, eval_env_fg = generate_data(bg_only=True, continuous=False, dataset='train')\n",
    "nfq_net = ContrastiveNFQNetwork(\n",
    "    state_dim=train_env_bg.state_dim, is_contrastive=is_contrastive, deep=True\n",
    ")\n",
    "optimizer = optim.Adam(nfq_net.parameters(), lr=1e-1)\n",
    "\n",
    "nfq_agent = NFQAgent(nfq_net, optimizer)\n",
    "\n",
    "# NFQ Main loop\n",
    "bg_success_queue = [0] * 3\n",
    "fg_success_queue = [0] * 3\n",
    "epochs_fg = 0\n",
    "eval_fg = 0\n",
    "train_rewards = [r[2] for r in train_rollouts]\n",
    "test_rewards = [r[2] for r in test_rollouts]\n",
    "print(\"Average Train Reward: \" + str(np.average(train_rewards)) + \" Average Test Reward: \" + str(np.average(test_rewards)))\n",
    "for k, epoch in enumerate(tqdm.tqdm(range(epoch + 1))):\n",
    "    state_action_b, target_q_values, groups = nfq_agent.generate_pattern_set(train_rollouts)\n",
    "\n",
    "    if not nfq_net.freeze_shared:\n",
    "        loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    eval_episode_length_fg, eval_success_fg, eval_episode_cost_fg = 0, 0, 0\n",
    "    if nfq_net.freeze_shared:\n",
    "        eval_fg += 1\n",
    "        if eval_fg > 50:\n",
    "            loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    (eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg) = nfq_agent.evaluate_car(eval_env_bg, render=False)\n",
    "    #(eval_episode_length_fg,eval_success_fg, eval_episode_cost_fg) = nfq_agent.evaluate_car(eval_env_fg, render=False)\n",
    "\n",
    "    bg_success_queue = bg_success_queue[1:]\n",
    "    bg_success_queue.append(1 if eval_success_bg else 0)\n",
    "\n",
    "    #fg_success_queue = fg_success_queue[1:]\n",
    "    #fg_success_queue.append(1 if eval_success_fg else 0)\n",
    "\n",
    "    if sum(bg_success_queue) == 3 and not nfq_net.freeze_shared == True:\n",
    "        if epochs_fg == 0:\n",
    "            epochs_fg = epoch\n",
    "        printed_bg = True\n",
    "        nfq_net.freeze_shared = True\n",
    "        if verbose:\n",
    "            print(\"FREEZING SHARED\")\n",
    "        if is_contrastive:\n",
    "            for param in nfq_net.layers_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            optimizer = optim.Adam(\n",
    "                itertools.chain(\n",
    "                    nfq_net.layers_fg.parameters(),\n",
    "                    nfq_net.layers_last_fg.parameters(),\n",
    "                ),\n",
    "                lr=1e-1,\n",
    "            )\n",
    "            nfq_agent._optimizer = optimizer\n",
    "\n",
    "    if sum(fg_success_queue) == 3:\n",
    "        printed_fg = True\n",
    "        break\n",
    "    \n",
    "    train_rollouts, train_env_bg, train_env_fg = generate_data(bg_only=True, continuous=False, agent=nfq_agent, dataset='train')\n",
    "    test_rollouts, eval_env_bg, eval_env_fg = generate_data(bg_only=True, continuous=False, agent=nfq_agent, dataset='train')\n",
    "    train_rewards = [r[2] for r in train_rollouts]\n",
    "    test_rewards = [r[2] for r in test_rollouts]\n",
    "    print(\"Average Train Reward: \" + str(np.average(train_rewards)) + \" Average Test Reward: \" + str(np.average(test_rewards)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a new network with the result of better rollouts\n",
    "* The evaluation is just changed to be regular resets (speed 0). \n",
    "* It doesn't really work. Even with the better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1001 [00:00<09:58,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False 0\n",
      "0 False 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 69/1001 [00:09<02:07,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREEZING SHARED\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 False 0\n",
      "0 True 100\n",
      "0 False 0\n"
     ]
    }
   ],
   "source": [
    "train_rollouts, train_env_bg, train_env_fg = generate_data(init_experience=200, bg_only=True, continuous=False)\n",
    "test_rollouts, eval_env_bg, eval_env_fg = generate_data(init_experience=200, bg_only=True, continuous=False, agent=nfq_agent, dataset='eval')\n",
    "is_contrastive=False\n",
    "epoch = 1000\n",
    "nfq_net = ContrastiveNFQNetwork(\n",
    "    state_dim=train_env_bg.state_dim, is_contrastive=is_contrastive, deep=False\n",
    ")\n",
    "optimizer = optim.Adam(nfq_net.parameters(), lr=1e-1)\n",
    "\n",
    "nfq_agent = NFQAgent(nfq_net, optimizer)\n",
    "\n",
    "bg_success_queue = [0] * 3\n",
    "fg_success_queue = [0] * 3\n",
    "epochs_fg = 0\n",
    "eval_fg = 0\n",
    "evaluations = 5\n",
    "for k, ep in enumerate(tqdm.tqdm(range(epoch + 1))):\n",
    "    state_action_b, target_q_values, groups = nfq_agent.generate_pattern_set(train_rollouts)\n",
    "\n",
    "    if not nfq_net.freeze_shared:\n",
    "        loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    eval_episode_length_fg, eval_success_fg, eval_episode_cost_fg = 0, 0, 0\n",
    "    if nfq_net.freeze_shared:\n",
    "        eval_fg += 1\n",
    "        if eval_fg > 50:\n",
    "            loss = nfq_agent.train((state_action_b, target_q_values, groups))\n",
    "\n",
    "    (eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg) = nfq_agent.evaluate_car(eval_env_bg, render=False)\n",
    "    bg_success_queue = bg_success_queue[1:]\n",
    "    bg_success_queue.append(1 if eval_success_bg else 0)\n",
    "\n",
    "    if sum(bg_success_queue) == 3 and not nfq_net.freeze_shared == True:\n",
    "        if epochs_fg == 0:\n",
    "            epochs_fg = epoch\n",
    "        printed_bg = True\n",
    "        nfq_net.freeze_shared = True\n",
    "        print(\"FREEZING SHARED\")\n",
    "        if is_contrastive:\n",
    "            for param in nfq_net.layers_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_shared.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            for param in nfq_net.layers_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in nfq_net.layers_last_fg.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            optimizer = optim.Adam(\n",
    "                itertools.chain(\n",
    "                    nfq_net.layers_fg.parameters(),\n",
    "                    nfq_net.layers_last_fg.parameters(),\n",
    "                ),\n",
    "                lr=1e-1,\n",
    "            )\n",
    "            nfq_agent._optimizer = optimizer\n",
    "        break\n",
    "    \n",
    "    if ep % 100 == 0:\n",
    "        for it in range(evaluations):\n",
    "            (eval_episode_length_bg,eval_success_bg,eval_episode_cost_bg) = nfq_agent.evaluate_car(eval_env_bg, render=False)\n",
    "            print(eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg)\n",
    "            train_env_bg.close()\n",
    "            eval_env_bg.close()\n",
    "for it in range(evaluations*10):\n",
    "    (eval_episode_length_bg,eval_success_bg,eval_episode_cost_bg) = nfq_agent.evaluate_car(eval_env_bg, render=False)\n",
    "    print(eval_episode_length_bg, eval_success_bg, eval_episode_cost_bg)\n",
    "    eval_env_bg.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research [~/.conda/envs/research/]",
   "language": "python",
   "name": "conda_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
