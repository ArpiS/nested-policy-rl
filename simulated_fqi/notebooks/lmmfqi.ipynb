{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle, os, csv, math, time\n",
    "from joblib import Parallel, delayed\n",
    "import datetime as dt\n",
    "from datetime import date, datetime, timedelta\n",
    "from collections import Counter\n",
    "import copy as cp\n",
    "import tqdm\n",
    "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import log_loss, f1_score, precision_score, recall_score, accuracy_score\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.ticker as ticker\n",
    "import collections\n",
    "#import shap\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "np.seterr(all=\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import sys\n",
    "from scipy import optimize\n",
    "sys.path.append('../models/')\n",
    "from lmm import LMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     11,
     12,
     14,
     16,
     18,
     22,
     26,
     33,
     36,
     53
    ]
   },
   "outputs": [],
   "source": [
    "def a2c(action):\n",
    "\tactions = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "\t#actions = [[0, 0], [0, 2], [3, 1], [4, 4]]\n",
    "\tclasses = []\n",
    "\tfor a in action:\n",
    "\t\ta = list(a)\n",
    "\t\tfor c in range(len(actions)):\n",
    "\t\t\tif actions[c] == a:\n",
    "\t\t\t\tclasses.append(c)\n",
    "\treturn classes\n",
    "\n",
    "def p2c(pred):\n",
    "\tif pred <= 0.25:\n",
    "\t\taction = [0, 0]\n",
    "\telif pred <= 0.5:\n",
    "\t\taction = [0, 1]\n",
    "\telif pred <= 0.75:\n",
    "\t\taction = [1, 0]\n",
    "\telse:\n",
    "\t\taction = [1, 1]\n",
    "\n",
    "# Mapping states to actions?\n",
    "def c2a(c):\n",
    "\td = {0: [0, 0], 1: [0, 1], 2: [1, 0], 3: [1, 1]}\n",
    "\treturn np.array([d[k] for k in c])\n",
    "\n",
    "def random_weights(size=5):\n",
    "\t# w = 2*np.random.uniform(size=size) - 1\n",
    "\tw = norm(np.random.uniform(size=size))\n",
    "\t# w / np.sum(np.abs(w))\n",
    "\n",
    "\treturn w\n",
    "\n",
    "def norm(vec):\n",
    "\treturn vec / np.sum(np.abs(vec))\n",
    "\n",
    "def learnBehaviour(training_set, test_set):\n",
    "\tfloc = \"behavior.pkl\"\n",
    "\t# if os.path.exists(floc):\n",
    "\t#    behaviour_pi = pickle.load(open(floc, 'rb'))\n",
    "\t# else:\n",
    "\t## Use a linear regression to predict behavior\n",
    "\tbehaviour_pi = LinearRegression()\n",
    "\tX = np.vstack((training_set['s'], test_set['s']))\n",
    "\tX = np.reshape(X, (-1, 10))\n",
    "\tprint(str(X.shape))\n",
    "\ty = a2c(np.vstack((training_set['a'], test_set['a'])))\n",
    "\tprint(str(len(y)))\n",
    "\tbehaviour_pi.fit(X, y)\n",
    "\tpickle.dump(behaviour_pi, open(floc, 'wb'))\n",
    "\n",
    "\treturn behaviour_pi\n",
    "\n",
    "def construct_dicts(train_tuples, test_tuples):\n",
    "\ttrain = {}\n",
    "\ttest = {}\n",
    "\telts = ['s', 'a', 'ns', 'r', 'ds', 'vnum']\n",
    "\tfor elt in elts:\n",
    "\t\ttrain[elt] = []\n",
    "\t\ttest[elt] = []\n",
    "\n",
    "\tfor tup in train_tuples:\n",
    "\t\ttrain['s'].append(tup[0])\n",
    "\t\ta = tup[1]\n",
    "\t\ttry:\n",
    "\t\t\ta = np.concatenate(a).ravel()\n",
    "\t\t\ta = list(a)\n",
    "\t\t\ttrain['a'].append(a)\n",
    "\t\texcept:\n",
    "\t\t\ttrain['a'].append(a)\n",
    "\t\ttrain['ns'].append(tup[2])\n",
    "\t\ttrain['r'].append(tup[3])\n",
    "\t\ttrain['ds'].append(tup[4])\n",
    "\t\ttrain['vnum'].append(tup[5])\n",
    "\n",
    "\tfor tup in test_tuples:\n",
    "\t\ttest['s'].append(tup[0])\n",
    "\t\ttry:\n",
    "\t\t\ta = tup[1]\n",
    "\t\t\ta = np.concatenate(a).ravel()\n",
    "\t\t\ta = list(a)\n",
    "\t\t\ttest['a'].append(a)\n",
    "\t\texcept:\n",
    "\t\t\ttest['a'].append(tup[1])\n",
    "\t\ttest['ns'].append(tup[2])\n",
    "\t\ttest['r'].append(tup[3])\n",
    "\t\ttest['ds'].append(tup[4])\n",
    "\t\ttest['vnum'].append(tup[5])\n",
    "\treturn train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 78.47it/s]\n"
     ]
    }
   ],
   "source": [
    "shape, scale = 2, 10\n",
    "transition_foreground = np.random.gamma(shape, scale, (12, 10))\n",
    "\n",
    "mu, sigma = 0, 4 # mean and standard deviation\n",
    "transition_background = np.random.normal(mu, sigma, (12, 10))\n",
    "\n",
    "mu, sigma = 0, 5\n",
    "reward_function = np.random.normal(mu, sigma, (12, 1))\n",
    "\n",
    "exploit = 0.6\n",
    "explore = 1-exploit\n",
    "num_samples = 100\n",
    "num_patients = 100\n",
    "actions = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "mu, sigma = 0, 4\n",
    "\n",
    "transition_tuples = []\n",
    "for k, pat in enumerate(tqdm.tqdm(range(num_patients))):\n",
    "\n",
    "\tflip = np.random.choice(2)\n",
    "\tif flip == 0:\n",
    "\t\tds = 'foreground'\n",
    "\telse:\n",
    "\t\tds = 'background'\n",
    "\t# Generate a random initial state\n",
    "\ts = np.random.normal(mu, sigma, (10, 1))\n",
    "\n",
    "\t# Generate all of the tuples for this patient\n",
    "\tfor i in range(num_samples):\n",
    "\t\tflip = random.uniform(0, 1)\n",
    "\t\t# Exploit\n",
    "\t\tif flip < exploit:\n",
    "\t\t\tall_rewards = []\n",
    "\t\t\tfor j, a in enumerate(actions):\n",
    "\t\t\t\ta = np.asarray(a)\n",
    "\t\t\t\ta = np.reshape(a, (2, 1))\n",
    "\t\t\t\ts_a = np.concatenate((s, a))\n",
    "\t\t\t\treward = np.dot(reward_function.T, s_a)\n",
    "\t\t\t\tall_rewards.append(reward)\n",
    "\n",
    "\t\t\tnoise = np.random.normal(0, 0.05, 1)\n",
    "\t\t\tall_rewards = np.asarray(all_rewards)\n",
    "\t\t\ta = actions[np.argmax(all_rewards)]\n",
    "\t\t\treward = np.max(all_rewards) + noise\n",
    "\n",
    "\t\t\tif ds == 'foreground':\n",
    "\t\t\t\tt_m = transition_foreground\n",
    "\t\t\telse:\n",
    "\t\t\t\tt_m = transition_background\n",
    "\t\t\tns = np.matmul(s_a.T, t_m) / np.linalg.norm(np.matmul(s_a.T, t_m), ord=2)\n",
    "\t\t\tns = np.add(ns, np.random.normal(0, 0.5, (1, 10)))  # Add noise\n",
    "\n",
    "\n",
    "\t\t# Explore\n",
    "\t\telse:\n",
    "\t\t\ta = np.asarray(actions[np.random.choice(3)])\n",
    "\t\t\ta = np.reshape(a, (2, 1))\n",
    "\t\t\ts_a = np.concatenate((s, a))  # concatenate the state and action\n",
    "\n",
    "\t\t\tif ds == 'foreground':\n",
    "\t\t\t\tt_m = transition_foreground\n",
    "\t\t\telse:\n",
    "\t\t\t\tt_m = transition_background\n",
    "\t\t\tns = np.matmul(s_a.T, t_m) / np.linalg.norm(np.matmul(s_a.T, t_m), ord=2)\n",
    "\t\t\tns = np.add(ns, np.random.normal(0, 0.5, (1, 10)))  # Add noise\n",
    "\n",
    "\t\t\treward = np.dot(reward_function.T, s_a) + np.random.normal(0, 0.5, 1)\n",
    "\n",
    "\t\t# Transition tuple includes state, action, next state, reward, ds\n",
    "\t\ttransition_tuples.append((list(s.flatten()), list(a), list(ns.flatten()), reward.flatten(), ds, i))\n",
    "\t\ts = ns.T\n",
    "\n",
    "split = int(0.8*len(transition_tuples))\n",
    "train_tuples = transition_tuples[:split]\n",
    "test_tuples = transition_tuples[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     33
    ]
   },
   "outputs": [],
   "source": [
    "class LMM():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, groups, method=\"bfgs\"):\n",
    "\n",
    "        n, p = X.shape\n",
    "        if method == \"bfgs\":\n",
    "\n",
    "            # Add columns of ones for intercept\n",
    "            X = np.hstack([np.ones((n, 1)), X])\n",
    "\n",
    "            def f(x):\n",
    "                beta_shared, beta_fg = x[:p+1], x[p+1:]\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                preds = X @ beta_shared + np.multiply(groups, X) @ beta_fg\n",
    "                # optimize MSE\n",
    "                return np.mean((y - preds) ** 2)\n",
    "\n",
    "            # Initial value of x \n",
    "            # (need 2 times the params to account for both groups)\n",
    "            x0 = np.random.normal(size=2*p + 2)\n",
    "\n",
    "            # Try with BFGS\n",
    "            xopt = optimize.minimize(f, x0, method='bfgs', options={'disp': 1})\n",
    "\n",
    "            self.coefs_shared = xopt.x[:p+1]\n",
    "            self.coefs_fg = xopt.x[p+1:]\n",
    "\n",
    "        # Not implemented for 12 dimensions\n",
    "        elif method == \"project\":\n",
    "\n",
    "            # Regression on all samples\n",
    "            reg = LinearRegression().fit(X, y)\n",
    "            coefs_shared = reg.coef_\n",
    "\n",
    "            # Get residuals for foreground group\n",
    "            X_fg = X[groups == 1]\n",
    "            y_fg = y[groups == 1]\n",
    "            X_fg_preds = reg.predict(X_fg)\n",
    "            X_residuals = y_fg - X_fg_preds\n",
    "\n",
    "            # Regress residuals on the foreground\n",
    "            reg = LinearRegression().fit(X_fg, X_residuals)\n",
    "            coefs_fg = reg.coef_\n",
    "\n",
    "            self.coefs_shared = coefs_shared\n",
    "            self.coefs_fg = coefs_fg\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Method must be one of [bfgs, project]\")\n",
    "\n",
    "    def predict(self, X, groups):\n",
    "        # Add columns of ones for intercept\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack([np.ones((n, 1)), X])\n",
    "\n",
    "        # Shared part + fg-specific part\n",
    "        preds = X @ self.coefs_shared + np.multiply(groups, X) @ self.coefs_fg\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LMMFQIagent():\n",
    "    def __init__(self, train_tuples, test_tuples, iters=150, gamma=0.99, batch_size=100, prioritize=False, estimator='lin',\n",
    "                 weights=np.array([1, 1, 1, 1, 1]) / 5., maxT=36):\n",
    "\n",
    "        self.iters = iters\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.prioritize_a = prioritize\n",
    "        self.training_set, self.test_set = construct_dicts(train_tuples, test_tuples)\n",
    "        self.raw_test = test_tuples\n",
    "\n",
    "        self.visits = {'train': len(train_tuples), 'test': len(test_tuples)}\n",
    "        self.NV = {'train': len(train_tuples), 'test': len(test_tuples)}\n",
    "        self.n_samples = len(self.training_set['s'])\n",
    "        _, self.unique_actions, self.action_counts, _ = self.sub_actions()\n",
    "        self.state_feats = [str(x) for x in range(10)]\n",
    "        self.n_features = len(self.state_feats)\n",
    "        self.reward_weights = weights\n",
    "        self.maxT = maxT\n",
    "        self.piB = learnBehaviour(self.training_set, self.test_set)\n",
    "        self.n_actions = 4\n",
    "\n",
    "        self.q_est = LMM()\n",
    "\n",
    "        self.piE = LinearRegression()\n",
    "        self.eval_est = LGBMRegressor(n_estimators=50, silent=True)\n",
    "\n",
    "    def sub_actions(self):\n",
    "\n",
    "        a = self.training_set['a']\n",
    "        a = list(a)\n",
    "\n",
    "        unique_actions = 0\n",
    "        action_counts = 0\n",
    "        n_actions = 0\n",
    "\n",
    "        unique_actions, action_counts = np.unique(a, axis=0, return_counts=True)\n",
    "        n_actions = len(unique_actions)\n",
    "\n",
    "        return a, unique_actions, action_counts, n_actions\n",
    "\n",
    "    def sampleTuples(self):\n",
    "        ids = list(np.random.choice(np.arange(self.n_samples), self.batch_size, replace=False))\n",
    "        batch = {}\n",
    "        for k in self.training_set.keys():\n",
    "            batch[k] = np.asarray(self.training_set[k], dtype=object)[ids]\n",
    "        batch['r'] = np.dot(batch['r'] * [1, 1, 10, 10, 100], self.reward_weights)\n",
    "        batch['s_ids'] = np.asarray(ids, dtype=int)\n",
    "        batch['ns_ids'] = np.asarray(ids, dtype=int) + 1\n",
    "        \n",
    "        return batch\n",
    "\n",
    "    def fitQ(self, batch, Q):\n",
    "\n",
    "        batch_foreground = {}\n",
    "        batch_background = {}\n",
    "        groups = []\n",
    "        elts = ['s', 's_ids', 'ns']\n",
    "        for el in elts:\n",
    "            batch_foreground[el] = []\n",
    "            batch_background[el] = []\n",
    "\n",
    "        for i in range(len(batch['s_ids'])):\n",
    "            if batch['ds'][i] == 'foreground':\n",
    "                batch_foreground['s_ids'].append(batch['s_ids'][i])\n",
    "                batch_foreground['s'].append(batch['s'][i])\n",
    "                batch_foreground['ns'].append(batch['ns'][i])\n",
    "            else:\n",
    "                batch_background['s_ids'].append(batch['s_ids'][i])\n",
    "                batch_background['s'].append(batch['s'][i])\n",
    "                batch_background['ns'].append(batch['ns'][i])\n",
    "                \n",
    "\n",
    "        for i in range(len(batch['s_ids'])):\n",
    "            if batch['ds'][i] == 'foreground':\n",
    "                groups.append(1)\n",
    "            else:\n",
    "                groups.append(0)\n",
    "        # input = [state action]\n",
    "        x_shared = np.hstack((batch['s'], batch['a']))\n",
    "        y_shared = batch['r'] + (self.gamma * np.max(Q[batch['ns_ids'], :], axis=1))\n",
    "        \n",
    "        groups = np.expand_dims(groups, axis=1)\n",
    "        self.q_est.fit(x_shared, y_shared, groups)\n",
    "\n",
    "        return batch_foreground, batch_background\n",
    "\n",
    "    def updateQtable(self, Qtable, batch_fg, batch_bg):\n",
    "        # Update for foregound using just foreground\n",
    "        # Update for background using shared\n",
    "\n",
    "        bg_size = len(batch_bg['s'])\n",
    "        fg_size = len(batch_fg['s'])\n",
    "        for i, a in enumerate(self.unique_actions):\n",
    "            Qtable[batch_bg['s_ids'], i] = self.q_est.predict(np.hstack((batch_bg['ns'], np.tile(a, (bg_size, 1)))), np.tile([0], (bg_size, 1)))\n",
    "            Qtable[batch_fg['s_ids'], i] = self.q_est.predict(np.hstack((batch_fg['ns'], np.tile(a, (fg_size, 1)))), np.tile([1], (fg_size, 1)))\n",
    "        return Qtable\n",
    "\n",
    "    def runFQI(self, repeats=10):\n",
    "\n",
    "        print('Learning policy')\n",
    "        meanQtable = np.zeros((self.n_samples + 1, self.n_actions))\n",
    "\n",
    "        for r in range(repeats):\n",
    "            print('Run', r, ':')\n",
    "            print('Initialize: get batch, set initial Q')\n",
    "            Qtable = np.zeros((self.n_samples + 1, self.n_actions))\n",
    "            Qdist = []\n",
    "\n",
    "            # print('Run FQI')\n",
    "            for iteration in range(self.iters):\n",
    "                # copy q-table\n",
    "                Qold = cp.deepcopy(Qtable)\n",
    "\n",
    "                # sample batch\n",
    "                batch = self.sampleTuples()\n",
    "\n",
    "                # learn q_est with samples, targets from batch\n",
    "                batch_foreground, batch_background = self.fitQ(batch, Qtable)\n",
    "\n",
    "                # update Q table for all s given new estimator\n",
    "                self.updateQtable(Qtable, batch_foreground, batch_background)\n",
    "\n",
    "                # check divergence from last estimate\n",
    "                Qdist.append(mean_absolute_error(Qold, Qtable))\n",
    "\n",
    "            # plt.plot(Qdist)\n",
    "            meanQtable += Qtable\n",
    "\n",
    "        meanQtable = meanQtable / repeats\n",
    "        print('Learn policy')\n",
    "\n",
    "        # Since the Q table is constructed contrastively, the policy is contrastive?\n",
    "        self.getPi(meanQtable)\n",
    "        return Qdist\n",
    "\n",
    "    def getPi(self, Qtable):\n",
    "        optA = np.argmax(Qtable, axis=1)\n",
    "        print(\"Opta: \", optA)\n",
    "        # print(\"Fitting to training set\")\n",
    "        # print(\"Optimal actions: \", optA)\n",
    "        self.piE.fit(self.training_set['s'], optA[:-1])\n",
    "\n",
    "    # print(\"Done Fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "10000\n",
      "Learning policy\n",
      "Run 0 :\n",
      "Initialize: get batch, set initial Q\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 35.533000\n",
      "         Iterations: 58\n",
      "         Function evaluations: 1647\n",
      "         Gradient evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 41.315070\n",
      "         Iterations: 59\n",
      "         Function evaluations: 1674\n",
      "         Gradient evaluations: 62\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 1592.996452\n",
      "         Iterations: 80\n",
      "         Function evaluations: 2592\n",
      "         Gradient evaluations: 96\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 677.894511\n",
      "         Iterations: 97\n",
      "         Function evaluations: 2835\n",
      "         Gradient evaluations: 105\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 53.419970\n",
      "         Iterations: 57\n",
      "         Function evaluations: 1620\n",
      "         Gradient evaluations: 60\n",
      "Divide-by-zero encountered: rhok assumed large\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 3186.462626\n",
      "         Iterations: 85\n",
      "         Function evaluations: 3596\n",
      "         Gradient evaluations: 133\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 1022.632763\n",
      "         Iterations: 61\n",
      "         Function evaluations: 1917\n",
      "         Gradient evaluations: 71\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 2448.742617\n",
      "         Iterations: 81\n",
      "         Function evaluations: 2808\n",
      "         Gradient evaluations: 104\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 8379.910631\n",
      "         Iterations: 97\n",
      "         Function evaluations: 3294\n",
      "         Gradient evaluations: 122\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 4351.588237\n",
      "         Iterations: 82\n",
      "         Function evaluations: 2592\n",
      "         Gradient evaluations: 96\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 8303.353589\n",
      "         Iterations: 87\n",
      "         Function evaluations: 2943\n",
      "         Gradient evaluations: 109\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 6025.077488\n",
      "         Iterations: 73\n",
      "         Function evaluations: 2187\n",
      "         Gradient evaluations: 81\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 4300.551104\n",
      "         Iterations: 86\n",
      "         Function evaluations: 2727\n",
      "         Gradient evaluations: 101\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 7673.815703\n",
      "         Iterations: 62\n",
      "         Function evaluations: 1944\n",
      "         Gradient evaluations: 72\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 3242.400558\n",
      "         Iterations: 100\n",
      "         Function evaluations: 3645\n",
      "         Gradient evaluations: 135\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 5305.366631\n",
      "         Iterations: 103\n",
      "         Function evaluations: 4521\n",
      "         Gradient evaluations: 167\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 12419.467548\n",
      "         Iterations: 139\n",
      "         Function evaluations: 5778\n",
      "         Gradient evaluations: 214\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 6957.440499\n",
      "         Iterations: 66\n",
      "         Function evaluations: 2052\n",
      "         Gradient evaluations: 76\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 18593.588014\n",
      "         Iterations: 108\n",
      "         Function evaluations: 3618\n",
      "         Gradient evaluations: 134\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 7011.013241\n",
      "         Iterations: 82\n",
      "         Function evaluations: 2565\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 15211.423114\n",
      "         Iterations: 60\n",
      "         Function evaluations: 2764\n",
      "         Gradient evaluations: 102\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 8503.096943\n",
      "         Iterations: 79\n",
      "         Function evaluations: 2592\n",
      "         Gradient evaluations: 96\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 3922.194000\n",
      "         Iterations: 57\n",
      "         Function evaluations: 2710\n",
      "         Gradient evaluations: 100\n",
      "Divide-by-zero encountered: rhok assumed large\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 10818.379402\n",
      "         Iterations: 94\n",
      "         Function evaluations: 3159\n",
      "         Gradient evaluations: 117\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 18028.181294\n",
      "         Iterations: 121\n",
      "         Function evaluations: 4374\n",
      "         Gradient evaluations: 162\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 10288.641326\n",
      "         Iterations: 85\n",
      "         Function evaluations: 2781\n",
      "         Gradient evaluations: 103\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 14631.530746\n",
      "         Iterations: 88\n",
      "         Function evaluations: 2808\n",
      "         Gradient evaluations: 104\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 14810.783977\n",
      "         Iterations: 65\n",
      "         Function evaluations: 2106\n",
      "         Gradient evaluations: 78\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 11759.655921\n",
      "         Iterations: 91\n",
      "         Function evaluations: 3375\n",
      "         Gradient evaluations: 125\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 5948.808745\n",
      "         Iterations: 105\n",
      "         Function evaluations: 3753\n",
      "         Gradient evaluations: 139\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 13103.223315\n",
      "         Iterations: 108\n",
      "         Function evaluations: 3780\n",
      "         Gradient evaluations: 140\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 18197.975401\n",
      "         Iterations: 63\n",
      "         Function evaluations: 2106\n",
      "         Gradient evaluations: 78\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 11255.408825\n",
      "         Iterations: 85\n",
      "         Function evaluations: 2808\n",
      "         Gradient evaluations: 104\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 18506.125794\n",
      "         Iterations: 75\n",
      "         Function evaluations: 2322\n",
      "         Gradient evaluations: 86\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 16993.776613\n",
      "         Iterations: 68\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 85\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 16672.782712\n",
      "         Iterations: 73\n",
      "         Function evaluations: 2700\n",
      "         Gradient evaluations: 100\n",
      "Divide-by-zero encountered: rhok assumed large\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 24881.194749\n",
      "         Iterations: 61\n",
      "         Function evaluations: 2079\n",
      "         Gradient evaluations: 77\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 16729.157488\n",
      "         Iterations: 72\n",
      "         Function evaluations: 2673\n",
      "         Gradient evaluations: 99\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 15835.601783\n",
      "         Iterations: 68\n",
      "         Function evaluations: 2160\n",
      "         Gradient evaluations: 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21767.767769\n",
      "         Iterations: 100\n",
      "         Function evaluations: 3402\n",
      "         Gradient evaluations: 126\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 14887.666396\n",
      "         Iterations: 125\n",
      "         Function evaluations: 4455\n",
      "         Gradient evaluations: 165\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 15501.452902\n",
      "         Iterations: 80\n",
      "         Function evaluations: 2835\n",
      "         Gradient evaluations: 105\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 26347.835730\n",
      "         Iterations: 115\n",
      "         Function evaluations: 5061\n",
      "         Gradient evaluations: 187\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 24867.487751\n",
      "         Iterations: 91\n",
      "         Function evaluations: 3105\n",
      "         Gradient evaluations: 115\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 26078.114700\n",
      "         Iterations: 76\n",
      "         Function evaluations: 2619\n",
      "         Gradient evaluations: 97\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 17956.007271\n",
      "         Iterations: 83\n",
      "         Function evaluations: 2565\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 15358.707496\n",
      "         Iterations: 75\n",
      "         Function evaluations: 2241\n",
      "         Gradient evaluations: 83\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 14397.138827\n",
      "         Iterations: 92\n",
      "         Function evaluations: 4278\n",
      "         Gradient evaluations: 158\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 19017.394277\n",
      "         Iterations: 74\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 85\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21586.159823\n",
      "         Iterations: 68\n",
      "         Function evaluations: 1998\n",
      "         Gradient evaluations: 74\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 18309.681468\n",
      "         Iterations: 119\n",
      "         Function evaluations: 4077\n",
      "         Gradient evaluations: 151\n",
      "Divide-by-zero encountered: rhok assumed large\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21051.050226\n",
      "         Iterations: 85\n",
      "         Function evaluations: 2754\n",
      "         Gradient evaluations: 102\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 19918.900610\n",
      "         Iterations: 99\n",
      "         Function evaluations: 3213\n",
      "         Gradient evaluations: 119\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 23451.458332\n",
      "         Iterations: 65\n",
      "         Function evaluations: 2187\n",
      "         Gradient evaluations: 81\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 19902.662777\n",
      "         Iterations: 93\n",
      "         Function evaluations: 3186\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21835.150493\n",
      "         Iterations: 93\n",
      "         Function evaluations: 3402\n",
      "         Gradient evaluations: 126\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21166.184977\n",
      "         Iterations: 76\n",
      "         Function evaluations: 2484\n",
      "         Gradient evaluations: 92\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 28192.916806\n",
      "         Iterations: 60\n",
      "         Function evaluations: 1998\n",
      "         Gradient evaluations: 74\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 34471.993575\n",
      "         Iterations: 82\n",
      "         Function evaluations: 2700\n",
      "         Gradient evaluations: 100\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21819.516000\n",
      "         Iterations: 102\n",
      "         Function evaluations: 3456\n",
      "         Gradient evaluations: 128\n",
      "Divide-by-zero encountered: rhok assumed large\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 18518.176322\n",
      "         Iterations: 140\n",
      "         Function evaluations: 5778\n",
      "         Gradient evaluations: 214\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 21435.138070\n",
      "         Iterations: 54\n",
      "         Function evaluations: 1782\n",
      "         Gradient evaluations: 66\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 30594.675587\n",
      "         Iterations: 67\n",
      "         Function evaluations: 2349\n",
      "         Gradient evaluations: 87\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 22515.681469\n",
      "         Iterations: 93\n",
      "         Function evaluations: 3078\n",
      "         Gradient evaluations: 114\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 24624.951092\n",
      "         Iterations: 141\n",
      "         Function evaluations: 5331\n",
      "         Gradient evaluations: 197\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 27125.579925\n",
      "         Iterations: 70\n",
      "         Function evaluations: 3306\n",
      "         Gradient evaluations: 122\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 22357.742032\n",
      "         Iterations: 105\n",
      "         Function evaluations: 3834\n",
      "         Gradient evaluations: 142\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 29834.500106\n",
      "         Iterations: 84\n",
      "         Function evaluations: 3213\n",
      "         Gradient evaluations: 119\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 22706.124083\n",
      "         Iterations: 78\n",
      "         Function evaluations: 2565\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 35808.787719\n",
      "         Iterations: 76\n",
      "         Function evaluations: 2484\n",
      "         Gradient evaluations: 92\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 24939.656754\n",
      "         Iterations: 123\n",
      "         Function evaluations: 4266\n",
      "         Gradient evaluations: 158\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 25841.573401\n",
      "         Iterations: 120\n",
      "         Function evaluations: 4266\n",
      "         Gradient evaluations: 158\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 36721.617392\n",
      "         Iterations: 73\n",
      "         Function evaluations: 2862\n",
      "         Gradient evaluations: 106\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 22908.931247\n",
      "         Iterations: 102\n",
      "         Function evaluations: 3726\n",
      "         Gradient evaluations: 138\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 28830.698077\n",
      "         Iterations: 61\n",
      "         Function evaluations: 1944\n",
      "         Gradient evaluations: 72\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 30136.023207\n",
      "         Iterations: 75\n",
      "         Function evaluations: 2322\n",
      "         Gradient evaluations: 86\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 28615.081242\n",
      "         Iterations: 74\n",
      "         Function evaluations: 2511\n",
      "         Gradient evaluations: 93\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 32378.375335\n",
      "         Iterations: 66\n",
      "         Function evaluations: 3090\n",
      "         Gradient evaluations: 114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 24396.751337\n",
      "         Iterations: 78\n",
      "         Function evaluations: 3024\n",
      "         Gradient evaluations: 112\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 26812.958169\n",
      "         Iterations: 85\n",
      "         Function evaluations: 2754\n",
      "         Gradient evaluations: 102\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 35102.980563\n",
      "         Iterations: 71\n",
      "         Function evaluations: 2376\n",
      "         Gradient evaluations: 88\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 25615.848669\n",
      "         Iterations: 78\n",
      "         Function evaluations: 2565\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 27342.488646\n",
      "         Iterations: 87\n",
      "         Function evaluations: 3279\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 28324.864874\n",
      "         Iterations: 89\n",
      "         Function evaluations: 3186\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 26818.233878\n",
      "         Iterations: 104\n",
      "         Function evaluations: 5153\n",
      "         Gradient evaluations: 190\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 32998.184850\n",
      "         Iterations: 97\n",
      "         Function evaluations: 3267\n",
      "         Gradient evaluations: 121\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 37354.493852\n",
      "         Iterations: 82\n",
      "         Function evaluations: 3132\n",
      "         Gradient evaluations: 116\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 35633.474354\n",
      "         Iterations: 78\n",
      "         Function evaluations: 2565\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 38206.527279\n",
      "         Iterations: 85\n",
      "         Function evaluations: 2727\n",
      "         Gradient evaluations: 101\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 45304.723295\n",
      "         Iterations: 94\n",
      "         Function evaluations: 3510\n",
      "         Gradient evaluations: 130\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 36100.626203\n",
      "         Iterations: 78\n",
      "         Function evaluations: 2754\n",
      "         Gradient evaluations: 102\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 26837.222900\n",
      "         Iterations: 75\n",
      "         Function evaluations: 2619\n",
      "         Gradient evaluations: 97\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 34174.665366\n",
      "         Iterations: 97\n",
      "         Function evaluations: 3078\n",
      "         Gradient evaluations: 114\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 30299.853443\n",
      "         Iterations: 98\n",
      "         Function evaluations: 3576\n",
      "         Gradient evaluations: 132\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 26126.342113\n",
      "         Iterations: 106\n",
      "         Function evaluations: 3483\n",
      "         Gradient evaluations: 129\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 38473.218764\n",
      "         Iterations: 64\n",
      "         Function evaluations: 2268\n",
      "         Gradient evaluations: 84\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 35463.332679\n",
      "         Iterations: 110\n",
      "         Function evaluations: 3483\n",
      "         Gradient evaluations: 129\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 42187.057102\n",
      "         Iterations: 116\n",
      "         Function evaluations: 4023\n",
      "         Gradient evaluations: 149\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 47345.112043\n",
      "         Iterations: 75\n",
      "         Function evaluations: 2430\n",
      "         Gradient evaluations: 90\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 29114.333721\n",
      "         Iterations: 72\n",
      "         Function evaluations: 2403\n",
      "         Gradient evaluations: 89\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 37663.492160\n",
      "         Iterations: 90\n",
      "         Function evaluations: 3078\n",
      "         Gradient evaluations: 114\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 37343.226043\n",
      "         Iterations: 124\n",
      "         Function evaluations: 4212\n",
      "         Gradient evaluations: 156\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 38410.949641\n",
      "         Iterations: 59\n",
      "         Function evaluations: 1971\n",
      "         Gradient evaluations: 73\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 33771.740197\n",
      "         Iterations: 88\n",
      "         Function evaluations: 2862\n",
      "         Gradient evaluations: 106\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 40134.252168\n",
      "         Iterations: 58\n",
      "         Function evaluations: 2376\n",
      "         Gradient evaluations: 88\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 43616.559581\n",
      "         Iterations: 82\n",
      "         Function evaluations: 2970\n",
      "         Gradient evaluations: 110\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 34754.132412\n",
      "         Iterations: 126\n",
      "         Function evaluations: 4185\n",
      "         Gradient evaluations: 155\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 33131.792791\n",
      "         Iterations: 74\n",
      "         Function evaluations: 2376\n",
      "         Gradient evaluations: 88\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 44129.550655\n",
      "         Iterations: 53\n",
      "         Function evaluations: 1917\n",
      "         Gradient evaluations: 71\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 41278.182909\n",
      "         Iterations: 107\n",
      "         Function evaluations: 5357\n",
      "         Gradient evaluations: 198\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 42723.426861\n",
      "         Iterations: 101\n",
      "         Function evaluations: 3618\n",
      "         Gradient evaluations: 134\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 30679.992415\n",
      "         Iterations: 98\n",
      "         Function evaluations: 3900\n",
      "         Gradient evaluations: 144\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 41156.361239\n",
      "         Iterations: 101\n",
      "         Function evaluations: 3375\n",
      "         Gradient evaluations: 125\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 42799.162960\n",
      "         Iterations: 76\n",
      "         Function evaluations: 2565\n",
      "         Gradient evaluations: 95\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 34705.042813\n",
      "         Iterations: 57\n",
      "         Function evaluations: 1998\n",
      "         Gradient evaluations: 74\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 31897.522697\n",
      "         Iterations: 116\n",
      "         Function evaluations: 4979\n",
      "         Gradient evaluations: 184\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 27897.686457\n",
      "         Iterations: 53\n",
      "         Function evaluations: 1809\n",
      "         Gradient evaluations: 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 47034.030589\n",
      "         Iterations: 92\n",
      "         Function evaluations: 2997\n",
      "         Gradient evaluations: 111\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 44447.429011\n",
      "         Iterations: 52\n",
      "         Function evaluations: 1971\n",
      "         Gradient evaluations: 73\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 28626.137079\n",
      "         Iterations: 108\n",
      "         Function evaluations: 5242\n",
      "         Gradient evaluations: 194\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 42492.214870\n",
      "         Iterations: 77\n",
      "         Function evaluations: 2673\n",
      "         Gradient evaluations: 99\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 39384.421489\n",
      "         Iterations: 109\n",
      "         Function evaluations: 3861\n",
      "         Gradient evaluations: 143\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 50677.380530\n",
      "         Iterations: 95\n",
      "         Function evaluations: 3240\n",
      "         Gradient evaluations: 120\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 42265.531690\n",
      "         Iterations: 57\n",
      "         Function evaluations: 2658\n",
      "         Gradient evaluations: 98\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 35907.127609\n",
      "         Iterations: 80\n",
      "         Function evaluations: 2835\n",
      "         Gradient evaluations: 105\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 41482.390924\n",
      "         Iterations: 103\n",
      "         Function evaluations: 3402\n",
      "         Gradient evaluations: 126\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 64743.262191\n",
      "         Iterations: 85\n",
      "         Function evaluations: 2943\n",
      "         Gradient evaluations: 109\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 46669.103303\n",
      "         Iterations: 90\n",
      "         Function evaluations: 2970\n",
      "         Gradient evaluations: 110\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 40433.861570\n",
      "         Iterations: 106\n",
      "         Function evaluations: 3483\n",
      "         Gradient evaluations: 129\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 56339.905943\n",
      "         Iterations: 54\n",
      "         Function evaluations: 1917\n",
      "         Gradient evaluations: 71\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 41572.448301\n",
      "         Iterations: 83\n",
      "         Function evaluations: 3186\n",
      "         Gradient evaluations: 118\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 38168.085094\n",
      "         Iterations: 99\n",
      "         Function evaluations: 4035\n",
      "         Gradient evaluations: 149\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 48823.564222\n",
      "         Iterations: 70\n",
      "         Function evaluations: 2403\n",
      "         Gradient evaluations: 89\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 34343.807261\n",
      "         Iterations: 81\n",
      "         Function evaluations: 2835\n",
      "         Gradient evaluations: 105\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 31793.837275\n",
      "         Iterations: 113\n",
      "         Function evaluations: 4710\n",
      "         Gradient evaluations: 174\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 48686.523294\n",
      "         Iterations: 128\n",
      "         Function evaluations: 5022\n",
      "         Gradient evaluations: 186\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 49343.069875\n",
      "         Iterations: 129\n",
      "         Function evaluations: 4698\n",
      "         Gradient evaluations: 174\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 54971.967922\n",
      "         Iterations: 67\n",
      "         Function evaluations: 2457\n",
      "         Gradient evaluations: 91\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 55003.909501\n",
      "         Iterations: 80\n",
      "         Function evaluations: 2592\n",
      "         Gradient evaluations: 96\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 53306.223484\n",
      "         Iterations: 83\n",
      "         Function evaluations: 2646\n",
      "         Gradient evaluations: 98\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 49174.953592\n",
      "         Iterations: 86\n",
      "         Function evaluations: 2889\n",
      "         Gradient evaluations: 107\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 46561.565366\n",
      "         Iterations: 88\n",
      "         Function evaluations: 3684\n",
      "         Gradient evaluations: 136\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 46843.316957\n",
      "         Iterations: 66\n",
      "         Function evaluations: 2295\n",
      "         Gradient evaluations: 85\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 37853.062751\n",
      "         Iterations: 74\n",
      "         Function evaluations: 2862\n",
      "         Gradient evaluations: 106\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 49078.920130\n",
      "         Iterations: 79\n",
      "         Function evaluations: 2538\n",
      "         Gradient evaluations: 94\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 52045.515293\n",
      "         Iterations: 66\n",
      "         Function evaluations: 2241\n",
      "         Gradient evaluations: 83\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 40884.112893\n",
      "         Iterations: 86\n",
      "         Function evaluations: 2781\n",
      "         Gradient evaluations: 103\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 41960.517036\n",
      "         Iterations: 136\n",
      "         Function evaluations: 5157\n",
      "         Gradient evaluations: 191\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 46316.562510\n",
      "         Iterations: 99\n",
      "         Function evaluations: 3402\n",
      "         Gradient evaluations: 126\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 35164.668648\n",
      "         Iterations: 80\n",
      "         Function evaluations: 2727\n",
      "         Gradient evaluations: 101\n",
      "Learn policy\n",
      "Opta:  [2 2 2 ... 2 3 0]\n"
     ]
    }
   ],
   "source": [
    "lmmfqi_agent = LMMFQIagent(train_tuples=train_tuples, test_tuples=test_tuples)\n",
    "Q_dist = lmmfqi_agent.runFQI(repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
