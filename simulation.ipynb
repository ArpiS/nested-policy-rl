{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "* Simulate RL data from two different distributions, generate transition tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate transition matrices, separate distributions for each one\n",
    "shape, scale = 2., 1. \n",
    "transition_foreground = np.random.gamma(shape, scale, (12, 10))\n",
    "\n",
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "transition_background = np.random.normal(mu, sigma, (12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reward function\n",
    "mu, sigma = 0, 2\n",
    "reward_function = np.random.normal(mu, sigma, (12, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "exploit = 0.8\n",
    "explore = 1-exploit\n",
    "num_samples = 1000\n",
    "actions = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "mu, sigma = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_tuples = []\n",
    "for i in range(num_samples):\n",
    "    # All initial states are generated from random normal\n",
    "    s = np.random.normal(mu, sigma, (10, 1))\n",
    "    \n",
    "    flip = random.uniform(0, 1)\n",
    "    # Exploit\n",
    "    if flip < exploit:\n",
    "        # Decide which transition matrix\n",
    "        flip = np.random.choice(1)\n",
    "        \n",
    "        all_rewards = []\n",
    "        for j, a in enumerate(actions):\n",
    "            a = np.asarray(a)\n",
    "            a = np.reshape(a, (2, 1))\n",
    "            s_a = np.concatenate((s, a))\n",
    "            reward = np.dot(reward_function.T, s_a)\n",
    "            all_rewards.append(reward)\n",
    "        \n",
    "        noise = np.random.normal(0, 0.01, 1)\n",
    "        all_rewards = np.asarray(all_rewards)\n",
    "        a = actions[np.argmax(all_rewards)]\n",
    "        reward = np.max(all_rewards) + noise\n",
    "        \n",
    "        if flip == 0:\n",
    "            ns = np.dot(s_a.T, transition_foreground) \n",
    "        else:\n",
    "            ns = np.dot(s_a.T, transition_background) \n",
    "        ns = np.add(ns , np.random.normal(0, 0.01, (1, 10))) # Add noise\n",
    "    # Explore\n",
    "    else:\n",
    "        a = np.asarray(actions[np.random.choice(3)])\n",
    "        a = np.reshape(a, (2, 1))\n",
    "        s_a = np.concatenate((s, a)) # concatenate the state and action\n",
    "        \n",
    "        # Decide which transition matrix\n",
    "        flip = np.random.choice(1)\n",
    "        if flip == 0:\n",
    "            ns = np.dot(s_a.T, transition_foreground)\n",
    "        else:\n",
    "            ns = np.dot(s_a.T, transition_background)\n",
    "        reward = np.dot(reward_function.T, s_a) + np.random.normal(0, 0.01, 1)\n",
    "        ns = np.add(ns , np.random.normal(0, 0.01, (1, 10))) # Add noise\n",
    "    \n",
    "    # Transition tuple includes state, action, next state, reward, indication of foreground/background\n",
    "    # 1 if foreground 0 if background\n",
    "    transition_tuples.append((s, list(a), ns, reward, 1 - flip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.73812211],\n",
       "        [ 0.96647785],\n",
       "        [ 0.39174267],\n",
       "        [ 0.79444951],\n",
       "        [ 1.51031674],\n",
       "        [-0.79999296],\n",
       "        [-1.09701259],\n",
       "        [-0.25926689],\n",
       "        [ 0.63007354],\n",
       "        [ 0.28462285]]),\n",
       " [1, 1],\n",
       " array([[ 4.56287606,  1.63101572, 18.00211842,  9.84517179, 17.63163768,\n",
       "         12.81082134, 11.40057412, 15.23515288,  7.19980815, 14.58702076]]),\n",
       " array([4.87665246]),\n",
       " 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_tuples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
