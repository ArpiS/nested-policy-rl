{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCPCA Implementation from: https://arxiv.org/abs/2012.07977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "inv = np.linalg.inv\n",
    "slogdet = np.linalg.slogdet\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCPCA:\n",
    "\n",
    "    def __init__(self, n_components=2, gamma=0.5):\n",
    "        \"\"\"Initialize PCPCA model.\n",
    "        \"\"\"\n",
    "        self.k = n_components\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Fit model via maximum likelihood estimation.\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == Y.shape[0]  # Should have same number of features\n",
    "        p, n, m = X.shape[0], X.shape[1], Y.shape[1]\n",
    "\n",
    "        # Get sample covariance\n",
    "        Cx, Cy = self._compute_sample_covariance(\n",
    "            X), self._compute_sample_covariance(Y)\n",
    "\n",
    "        # Differential covariance\n",
    "        Cdiff = n * Cx - self.gamma * m * Cy\n",
    "\n",
    "        # Eigendecomposition\n",
    "        eigvals, U = np.linalg.eigh(Cdiff)\n",
    "\n",
    "        # Sort by eigenvalues and truncate to number of components\n",
    "        sorted_idx = np.argsort(-eigvals)\n",
    "        eigvals = eigvals[sorted_idx]\n",
    "        U = U[:, sorted_idx]\n",
    "        Lambda = np.diag(eigvals)\n",
    "        Lambda, U = Lambda[:self.k, :self.k], U[:, :self.k]\n",
    "\n",
    "        # MLE for sigma2\n",
    "        sigma2_mle = 1 / (p - self.k) * \\\n",
    "            np.sum(eigvals[self.k:] / (n - self.gamma * m))\n",
    "\n",
    "        # MLE for W\n",
    "        Lambda_scaled = Lambda / (n - self.gamma * m)\n",
    "        W_mle = U @ sqrtm(Lambda_scaled - sigma2_mle * np.eye(self.k))\n",
    "\n",
    "        self.sigma2_mle = sigma2_mle\n",
    "        self.W_mle = W_mle\n",
    "\n",
    "    def transform(self, X, Y):\n",
    "        \"\"\"Embed data using fitted model.\n",
    "        \"\"\"\n",
    "        \n",
    "        t = self.W_mle.T @ X, self.W_mle.T @ Y\n",
    "        return t\n",
    "\n",
    "    def fit_transform(self, X, Y):\n",
    "        self.fit(X, Y)\n",
    "        t = self.transform(X, Y)\n",
    "        return t\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Sample from the fitted model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_gamma_bound(self, X, Y):\n",
    "        \"\"\"Compute the upper bound on gamma such that sigma2 > 0.\n",
    "        \"\"\"\n",
    "        p = X.shape[0]\n",
    "        Cx = self._compute_sample_covariance(X)\n",
    "        Cy = self._compute_sample_covariance(Y)\n",
    "        Cx_eigvals = -np.sort(-np.linalg.eigvals(Cx))\n",
    "        Cy_eigvals = -np.sort(-np.linalg.eigvals(Cy))\n",
    "\n",
    "        gamma_bound = np.sum(Cx_eigvals[self.k-1:]) / \\\n",
    "            ((p - self.k) * Cy_eigvals[0])\n",
    "        return gamma_bound\n",
    "\n",
    "    def _compute_sample_covariance(self, data):\n",
    "        \"\"\"Compute sample covariance where data is a p x n matrix.\n",
    "        \"\"\"\n",
    "        n = data.shape[1]\n",
    "        cov = 1 / n * data @ data.T\n",
    "        return cov\n",
    "\n",
    "    # Indication matrix for observed values\n",
    "    def make_L(self, X):\n",
    "        p = X.shape[0]\n",
    "        unobserved_idx = np.where(np.isnan(X))[0]\n",
    "        observed_idx = np.setdiff1d(np.arange(p), unobserved_idx)\n",
    "        L = np.zeros((observed_idx.shape[0], p))\n",
    "        for ii, idx in enumerate(observed_idx):\n",
    "            L[ii, idx] = 1\n",
    "        return L\n",
    "\n",
    "    # Indication matrix for unobserved values\n",
    "    def make_P(self, X):\n",
    "        p = X.shape[0]\n",
    "        unobserved_idx = np.where(np.isnan(X))[0]\n",
    "        P = np.zeros((unobserved_idx.shape[0], p))\n",
    "        for ii, idx in enumerate(unobserved_idx):\n",
    "            P[ii, idx] = 1\n",
    "        return P\n",
    "\n",
    "    def impute_missing_data(self, X):\n",
    "        p, n = X.shape\n",
    "        W, sigma2 = self.W_mle, self.sigma2_mle\n",
    "\n",
    "        # Indication matrices for observed values\n",
    "        Ls = [self.make_L(X[:, ii]) for ii in range(n)]\n",
    "\n",
    "        # Indication matrices for unobserved values\n",
    "        Ps = [self.make_P(X[:, ii]) for ii in range(n)]\n",
    "\n",
    "        # Cov between observed features\n",
    "        As = [Ls[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "\n",
    "        # Cov between unobserved features\n",
    "        Cs = [Ps[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ps[ii].T for ii in range(n)]\n",
    "\n",
    "        # Cov between unobserved/observed features\n",
    "        Fs = [Ps[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "\n",
    "        # Find conditional mean of unobserved values\n",
    "        X_imputed = X.copy()\n",
    "        for ii in range(n):\n",
    "            unobserved_idx = np.where(np.isnan(X[:, ii]))[0]\n",
    "            observed_idx = np.setdiff1d(np.arange(p), unobserved_idx)\n",
    "            xhat_u_ii = Fs[ii] @ inv(As[ii]) @ X_imputed[:, ii][observed_idx]\n",
    "            X_imputed[unobserved_idx, ii] = xhat_u_ii\n",
    "\n",
    "        return X_imputed\n",
    "\n",
    "\n",
    "    def gradient_descent_missing_data(self, X, Y, n_iter=500, verbose=True):\n",
    "\n",
    "        def grads(X, Y, W, sigma2, gamma):\n",
    "            p, n = X.shape\n",
    "            m = Y.shape[1]\n",
    "\n",
    "            # Indication matrices\n",
    "            Ls = [self.make_L(X[:, ii]) for ii in range(n)]\n",
    "            Ms = [self.make_L(Y[:, ii]) for ii in range(m)]\n",
    "\n",
    "            As = [Ls[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "            Bs = [Ms[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ms[ii].T for ii in range(m)]\n",
    "\n",
    "            running_sum_W_X = np.zeros((p, p))\n",
    "            running_sum_sigma2_X = 0\n",
    "            for ii in range(n):\n",
    "                L, A = Ls[ii], As[ii]\n",
    "                x = L @ np.nan_to_num(X[:, ii], nan=0)\n",
    "                Di = L.shape[0]\n",
    "                A_inv = inv(A)\n",
    "\n",
    "                curr_summand_W = L.T @ A_inv @ (np.eye(Di) - np.outer(x, x) @ A_inv) @ L\n",
    "                running_sum_W_X += curr_summand_W\n",
    "\n",
    "                curr_summand_sigma2 = np.trace(A_inv @ L @ L.T) - np.trace(A_inv @ np.outer(x, x) @ A_inv @ L @ L.T)\n",
    "                running_sum_sigma2_X += curr_summand_sigma2\n",
    "\n",
    "            running_sum_W_Y = np.zeros((p, p))\n",
    "            running_sum_sigma2_Y = 0\n",
    "            for jj in range(m):\n",
    "                M, B = Ms[jj], Bs[jj]\n",
    "                y = M @ np.nan_to_num(Y[:, jj], nan=0)\n",
    "                Ej = M.shape[0]\n",
    "                B_inv = inv(B)\n",
    "\n",
    "                curr_summand_W = M.T @ B_inv @ (np.eye(Ej) - np.outer(y, y) @ B_inv) @ M\n",
    "                running_sum_W_Y += curr_summand_W\n",
    "\n",
    "                curr_summand_sigma2 = np.trace(B_inv @ M @ M.T) - np.trace(B_inv @ np.outer(y, y) @ B_inv @ M @ M.T)\n",
    "                running_sum_sigma2_Y += curr_summand_sigma2\n",
    "\n",
    "            W_grad = -(running_sum_W_X - gamma * running_sum_W_Y) @ W\n",
    "            sigma2_grad = -0.5 * running_sum_sigma2_X + gamma/2.0 * running_sum_sigma2_Y\n",
    "\n",
    "            return W_grad, sigma2_grad\n",
    "\n",
    "        def log_likelihood(X, Y, W, sigma2, gamma):\n",
    "            p, n = X.shape\n",
    "            m = Y.shape[1]\n",
    "            Ls = [self.make_L(X[:, ii]) for ii in range(n)]\n",
    "            Ms = [self.make_L(Y[:, ii]) for ii in range(m)]\n",
    "\n",
    "            As = [Ls[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "            Bs = [Ms[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ms[ii].T for ii in range(m)]\n",
    "\n",
    "            running_sum_X = 0\n",
    "            for ii in range(n):\n",
    "                L = Ls[ii]\n",
    "                A = As[ii]\n",
    "                x = L @ np.nan_to_num(X[:, ii], nan=0)\n",
    "                Di = L.shape[0]\n",
    "                A_inv = inv(A)\n",
    "\n",
    "                curr_summand = Di * np.log(2 * np.pi) + slogdet(A)[1] + np.trace(A_inv @ np.outer(x, x))\n",
    "                running_sum_X += curr_summand\n",
    "\n",
    "            running_sum_Y = 0\n",
    "            for ii in range(m):\n",
    "                M = Ms[ii]\n",
    "                B = Bs[ii]\n",
    "                y = M @ np.nan_to_num(Y[:, ii], nan=0)\n",
    "                Ei = M.shape[0]\n",
    "                B_inv = inv(B)\n",
    "\n",
    "                curr_summand = Ei * np.log(2 * np.pi) + slogdet(B)[1] + np.trace(B_inv @ np.outer(y, y))\n",
    "                running_sum_Y += curr_summand\n",
    "\n",
    "            LL = -0.5 * running_sum_X + gamma/2.0 * running_sum_Y\n",
    "\n",
    "            return LL\n",
    "\n",
    "        X_col_means = np.nanmean(X.T, axis=0)\n",
    "        Y_col_means = np.nanmean(Y.T, axis=0)\n",
    "\n",
    "        # Find indices that you need to replace\n",
    "        inds_X = np.where(np.isnan(X.T))\n",
    "        inds_Y = np.where(np.isnan(Y.T))\n",
    "\n",
    "        # Place column means in the indices. Align the arrays using take\n",
    "        X_copy, Y_copy = X.copy(), Y.copy()\n",
    "        X_copy, Y_copy = X_copy.T, Y_copy.T\n",
    "        X_copy[inds_X] = np.take(X_col_means, inds_X[1])\n",
    "        Y_copy[inds_Y] = np.take(Y_col_means, inds_Y[1])\n",
    "        X_copy -= X_copy.mean(0)\n",
    "        Y_copy -= Y_copy.mean(0)\n",
    "        X_copy, Y_copy = X_copy.T, Y_copy.T\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        pcpca_init = PCPCA(gamma=self.gamma, n_components=self.k)\n",
    "        pcpca_init.fit(X_copy, Y_copy)\n",
    "        W, sigma2 = pcpca_init.W_mle, 2  # pcpca_init.sigma2_mle\n",
    "\n",
    "        # Adam\n",
    "        alpha = 0.01\n",
    "        beta_1 = 0.9\n",
    "        beta_2 = 0.999  # initialize the values of the parameters\n",
    "        epsilon = 1e-8\n",
    "        m_t = 0\n",
    "        v_t = 0\n",
    "        m_t_sigma2 = 0\n",
    "        v_t_sigma2 = 0\n",
    "        t = 0\n",
    "        # W = np.random.normal(size=(X.shape[0], self.k))\n",
    "        # sigma2 = 3.0\n",
    "\n",
    "        ll_trace = []\n",
    "        ll_last = 0\n",
    "        for iter_num in range(n_iter):  # till it gets converged\n",
    "            t += 1\n",
    "            # computes the gradient of the stochastic function\n",
    "            g_t_W, g_t_sigma2 = grads(X, Y, W, sigma2, self.gamma)\n",
    "\n",
    "            # W\n",
    "            # updates the moving averages of the gradient\n",
    "            m_t = beta_1*m_t + (1-beta_1)*g_t_W\n",
    "            # updates the moving averages of the squared gradient\n",
    "            v_t = beta_2*v_t + (1-beta_2)*(g_t_W*g_t_W)\n",
    "            # calculates the bias-corrected estimates\n",
    "            m_cap = m_t/(1-(beta_1**t))\n",
    "            # calculates the bias-corrected estimates\n",
    "            v_cap = v_t/(1-(beta_2**t))\n",
    "            W_prev = W\n",
    "            # updates the parameters\n",
    "            W = W + (alpha*m_cap)/(np.sqrt(v_cap)+epsilon)\n",
    "\n",
    "            # sigma2\n",
    "            # updates the moving averages of the gradient\n",
    "            m_t_sigma2 = beta_1*m_t_sigma2 + (1-beta_1)*g_t_sigma2\n",
    "            # updates the moving averages of the squared gradient\n",
    "            v_t_sigma2 = beta_2*v_t_sigma2 + (1-beta_2)*(g_t_sigma2*g_t_sigma2)\n",
    "            # calculates the bias-corrected estimates\n",
    "            m_cap = m_t_sigma2/(1-(beta_1**t))\n",
    "            # calculates the bias-corrected estimates\n",
    "            v_cap = v_t_sigma2/(1-(beta_2**t))\n",
    "            sigma2_prev = sigma2\n",
    "            # updates the parameters\n",
    "            sigma2 = sigma2 + (alpha*m_cap)/(np.sqrt(v_cap)+epsilon)\n",
    "\n",
    "            # Threshold\n",
    "            sigma2 = max(sigma2, 1e-4)\n",
    "\n",
    "            if verbose and (iter_num % 20) == 0:\n",
    "                ll = log_likelihood(X, Y, W, sigma2, self.gamma)\n",
    "                if np.abs(ll - ll_last) < 0.1:\n",
    "                    break\n",
    "                ll_last = ll\n",
    "                print(\"Iter: {} \\t LL: {}\".format(iter_num, round(ll, 2)))\n",
    "\n",
    "        self.sigma2_mle = sigma2\n",
    "        self.W_mle = W\n",
    "        return W, sigma2\n",
    "\n",
    "    def _create_permuation_matrix(self, idx):\n",
    "\n",
    "        P = np.zeros((idx.shape[0], idx.shape[0]))\n",
    "        for ii, curr_idx in enumerate(idx):\n",
    "            P[ii, curr_idx] = 1\n",
    "        return P\n",
    "\n",
    "    def _compute_Exxi(self, x, A):\n",
    "\n",
    "        # Arrange data into observed and unobserved\n",
    "        observed_idx = np.where(~np.isnan(x))[0]\n",
    "        unobserved_idx = np.setdiff1d(np.arange(self.p), observed_idx)\n",
    "        n_observed, n_unobserved = len(observed_idx), len(unobserved_idx)\n",
    "        xo = x[observed_idx]\n",
    "        xu = x[unobserved_idx]\n",
    "\n",
    "        # Put A into block matrix form\n",
    "        A_sorted_idx = np.concatenate([observed_idx, unobserved_idx])\n",
    "        A = A[A_sorted_idx, :][:, A_sorted_idx]\n",
    "\n",
    "        # Pull out blocks\n",
    "        Aoo = A[:n_observed, :n_observed]\n",
    "        Auo = A[n_observed:, :n_observed]\n",
    "        Aou = Auo.T\n",
    "        Auu = A[n_observed:, n_observed:]\n",
    "\n",
    "        # Compute Mi/Mj\n",
    "        Aoo_inv = np.linalg.inv(Aoo)\n",
    "        Ai_lowerright = Auu - Auo @ Aoo_inv @ Aou\n",
    "        Ai = np.block([\n",
    "            [np.zeros((n_observed, n_observed)),\n",
    "             np.zeros((n_observed, n_unobserved))],\n",
    "            [np.zeros((n_unobserved, n_observed)),    Ai_lowerright]])\n",
    "\n",
    "        # Compute mui/muj\n",
    "        mui = np.concatenate([xo, Auo @ Aoo_inv @ xo])\n",
    "\n",
    "        # Compute expectation of outer product\n",
    "        Exxi = Ai + np.outer(mui, mui)\n",
    "\n",
    "        # Permute back to original indices\n",
    "        P = self._create_permuation_matrix(A_sorted_idx)\n",
    "        Exxi = P @ Exxi @ P\n",
    "\n",
    "        return Exxi\n",
    "\n",
    "    def _compute_Co(self, X, Y, A):\n",
    "\n",
    "        Exxis = np.zeros((self.p, self.p))\n",
    "        for ii in range(self.n):\n",
    "            Exxi = self._compute_Exxi(X[:, ii], A)\n",
    "            Exxis += Exxi\n",
    "\n",
    "        Eyyjs = np.zeros((self.p, self.p))\n",
    "        for jj in range(self.m):\n",
    "            Eyyj = self._compute_Exxi(Y[:, jj], A)\n",
    "            Eyyjs += Eyyj\n",
    "\n",
    "        Co = Exxis - self.gamma * Eyyjs\n",
    "        return Co\n",
    "\n",
    "    def _log_likelihood(self, X, W, sigma2):\n",
    "        p = X.shape[0]\n",
    "        return np.sum(multivariate_normal.logpdf(X.T, mean=np.zeros(p), cov=W @ W.T + sigma2 * np.eye(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background shape:  (25170, 35)\n",
      "Foreground_a shape:  (13, 35)\n",
      "Foreground_b shape:  (1695, 35)\n",
      "Foreground shape:  (1708, 39)\n"
     ]
    }
   ],
   "source": [
    "# Application to covid data\n",
    "m = 200\n",
    "data = pd.read_csv(\"covid_12h.csv\")\n",
    "data = data.dropna()\n",
    "columns = ['ALBUMIN', 'ANION GAP',\n",
    "       'BASE EXCESS', 'BICARBONATE', 'BILIRUBIN', 'CALCIUM',\n",
    "       'CARBOXYHEMOGLOBIN', 'CHLORIDE', 'CREATININE', 'HEMATOCRIT',\n",
    "       'HEMOGLOBIN', 'INSPIRED OXYGEN', 'INTERNATIONAL NORMALIZED RATIO',\n",
    "       'LACTATE', 'METHEMOGLOBIN', 'PARTIAL THROMBOPLASTIN TIME', 'PCO2', 'PH',\n",
    "       'PLATELETS', 'PO2', 'POTASSIUM', 'SODIUM', 'UREA NITROGEN',\n",
    "       'URINE OUTPUT', 'WHITE BLOOD CELLS', 'FIO2', 'PEEP', 'OXYGEN (L)',\n",
    "       'Respiratory Aids', 'Nonsteroidal Anti-inflammatory Agents (NSAIDs)',\n",
    "       'Corticosteroids - Topical', 'Mineralocorticoids',\n",
    "       'Glucocorticosteroids', 'Influenza Agents', 'Antiretrovirals']\n",
    "\n",
    "\n",
    "background = data[data['Glucocorticosteroids'] == 0][columns]\n",
    "foreground = data[data['Glucocorticosteroids'] == 1]\n",
    "foreground_a = foreground[foreground['is_deceased_next_t'] == 1][columns]\n",
    "foreground_b = foreground[foreground['is_deceased_next_t'] == 0][columns]\n",
    "\n",
    "\n",
    "print(\"Background shape: \", background.shape)\n",
    "print(\"Foreground_a shape: \", foreground_a.shape)\n",
    "print(\"Foreground_b shape: \", foreground_b.shape)\n",
    "print(\"Foreground shape: \", foreground.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pcpca(X, Y):\n",
    "    gamma_range = [0, 0.01, 0.05, 0.06]\n",
    "    k = 1\n",
    "    plt.figure(figsize=(len(gamma_range) * 7, 5))\n",
    "    for ii, gamma in enumerate(gamma_range):\n",
    "        pcpca = PCPCA(gamma=gamma, n_components=k)\n",
    "        pcpca.fit(X, Y)\n",
    "\n",
    "    #     plt.subplot(1, len(gamma_range), ii+1)\n",
    "    #     if gamma == 0:\n",
    "    #         plt.title(r'$\\gamma^\\prime$={}  (PPCA)'.format(gamma))\n",
    "    #     else:\n",
    "    #         plt.title(r'$\\gamma^\\prime$={}'.format(gamma))\n",
    "    #     plt.scatter(X[0, :283], X[1, :283], alpha=0.5, label=\"INR == -1\", s=80, color=\"green\")\n",
    "    #     plt.scatter(X[0, 283:], X[1, 283:], alpha=0.5, label=\"INR > -1\", s=80, color=\"orange\")\n",
    "    #     plt.scatter(Y[0, :], Y[1, :], alpha=0.5, label=\"Background\", s=80, color=\"gray\")\n",
    "    #     plt.legend()\n",
    "    #     plt.xlim([-7, 7])\n",
    "    #     plt.ylim([-7, 7])\n",
    "\n",
    "    #     origin = np.array([[0], [0]])  # origin point\n",
    "    #     # This is the line that distinguishes between the two classes.\n",
    "    #     abline(slope=pcpca.W_mle[1, 0] / pcpca.W_mle[0, 0], intercept=0)\n",
    "\n",
    "        #print(\"W shape: \", pcpca.W_mle)\n",
    "        print(\"Gamma: \" + str(gamma) + \" MSE: \" + str(pcpca.sigma2_mle))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #import ipdb\n",
    "    #ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 1 : Normalize (subtract mean, divide by sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def normalize(df):\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.StandardScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled).to_numpy()\n",
    "\n",
    "background_norm = normalize(background)\n",
    "foreground_a_norm = normalize(foreground_a)\n",
    "foreground_b_norm = normalize(foreground_b)\n",
    "foreground_norm = np.concatenate([foreground_a_norm, foreground_b_norm], axis=0)\n",
    "X = foreground_norm\n",
    "Y = background_norm\n",
    "X, Y = X.T, Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0 MSE: 0.8221740438132632\n",
      "Gamma: 0.01 MSE: 0.8052983296327216\n",
      "Gamma: 0.05 MSE: 0.5331550892653986\n",
      "Gamma: 0.06 MSE: 0.02131817331392175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2016x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_pcpca(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 2 : Project the data onto W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyk0lEQVR4nO3de3xU9Z3/8deHzORGHG4JokEIKm2gyC1BoALtFlapVay1lrTWS1uhN2ur21at3dbuVnerva21rUK12q1L/NUWrbvWWusFsIoSRY0SRRQi4ZagEGKYJJN8f3+cyTi5kZCZZE6S9/PxGJg53zPf85nvTOYz33O+53vMOYeIiIjfDEt1ACIiIp1RghIREV9SghIREV9SghIREV9SghIREV9SghIREV9SghrizKzOzE4cKPUONWZWYGbOzAKpjkWkvylBDUBmtt3MDkeTwF4z+62Z5fSmLudcjnPujQTjedzMLk12vclmZnea2Q97+dxPm9kr7Zb9rYtlVycSp/SOeX5kZvujtxvNzI6w/mIzqzCzejN7zMwmtiufbWbr4v7Ovt73r0LiKUENXGc753KA2cAc4LvtV9Cv7qR6AphiZnkQa9sZQHa7ZfOBdSmLcmhbCXwc732ZDpwFfLGzFc0sF/gT8K/AaGATcE+78oeA24AxwMnAw30XunTKOafbALsB24ElcY9vAv43et8BXwW2Am9Gl60AXgfeBv4MHB/3XAecHL2fAfwYqAT2ArcCWXHrngNsBmqBbcBS4HqgGQgDdcAtndR7J/BL4P+AQ8BG4KS4ek8HXgUOAr/CSwaXdvHaM4CfA7uit58DGdGyDwM7gX8B9gG7gc9Fy1YCTUBjNM4HosunAI8DB4CXgWVHaPdtwHnR+6cCjwF3tVtWD6T34P37FvAi8C5wO3As8Jdo+zwCjIquWxBty0D08Yjo+ruBKuCHQFoPPzeT8JJn6zZ+Cfw+rvwPwJ7o+7AO+EBc2Z3R9+Yv0fZ7EhgXbf93gApgVm9eY3fbPoq/i38AK+MefwF4uot1VwL/iHs8HDgMFEYf3wD8d6r/1of6TT2oAc7MTgDOBJ6PW/xxYC4w1cw+AvwH8CngOGAHUNpFdT8C3gfMxPvFmA98L7qdU4Hf4X3pjAQWAdudc9cC64HLnLdb77Iu6v408ANgFF6yvD5aby5wL3AN3i/VV4EPHuElXwvMi8Y4Ay8pxPcex+F9iefjfUH90sxGOedWAXcDN0bjPNvMgsADeL+MxwJfA+42s/d3se110ddN9P/1wIZ2y552zjUeIf5W5wH/jNfeZ+N9cX8HyMXbs3F5F8+7C4jgvT+z8JL7pV2s297/AM/gtfN1wIXtyv8CTMZri+fw2ivep/DaOhdoAJ6Krtf6Hv40gdfY5bbN7GozO9DVLa6ODwAvxD1+IbqsM23Wdc69i/cDpHX9ecDbZvYPM9tnZg+Y2YQu6pK+kuoMqdvR3/B+ndbh/erfgffLNita5oCPxK17O96XcuvjHLyeREHc+icDhvdLN75nM5/3emG3AT/rIp7HadfjoWMP6jdxZWcCFdH7FwFPxZUZ8Fb7+uLKtwFnxj0+Ay9RgteDOky0txFdtg+YFxfHD+PKFuL9ah8Wt2wNcF0X274EeD56/368L9/Cdsu+38P374K4x38Efh33+GvAfdH7BdG2DOD1QBpo26v9NPBYD7Y5AS+xZcct+z1xPah264+MbndEXNutbhfjlrjHpwAHevMau9v2UfxdNBPtAUUfT47WY52sezvwn+2WPQlcEr3/Gt7f1xwgE7gZePJo4tEt8ZuOUQxcH3fOPdJF2Vtx94/H+0UKgHOuzsz24/UwtsetlwdkA2Vxx5UNSIvePwF4MIF498Tdr8dLlK3xxeJ1zjkz23mEeo7HS8qtdkSXtdrvnIt0sa3O6nrLOdfSrr78LtZfB9xuZqPwfmFfEG3P46LLFuDt8uqJvXH3D3fyuLOYJwJBYHfcezSMtu93V44H3nbO1cctewvvfcXM0vB6tefjfRZa2yQXb7dbb2Lu0fo93HZP1AGhuMchoM5FM04367aufyguvrXOuWejMf4AqDGzEc65o4lJEqBdfINT/B/kLrwvNgDMbDjeLp6qds+pwfuj/IBzbmT0NsJ5AzHA+zI7qQfbO1q7gfFx8Vn84060eT14PYNdPdxW+zh3ASeYWfzfwQQ6to33ZG9U4i684xeVzrm6aNFT0WU5wNM9jKU33sLrQeXGvUch51xXu7Hi7QZGm1l23LIT4u5/Bu8Y4xK8XaQF0eVdjoJLoiNu28y+Ex1J1+ktrp6X8Xb7tpoRXdaZNutG/y5Oilv/Rdp+Xlrv90d7SJQS1OD3P8DnzGymmWXgHfzd6JzbHr9StBexGviZmY0FMLN8Mzsjusrt0XoWm9mwaFlhtGwv0Ntznv4POMXMPh4dBfdVvONIXVkDfNfM8qLHr76Ht6uqJ9rHuRFvt+a3zSxoZh/GO1bS1TE68I47XRn9v9WG6LJNzrnDPYzlqDnnduMdL/uJmYWi78NJZvYhaHPOVEEnz92BN1LtOjNLN7P5eK+11TF4yW8/Xk/6hr56HZ044radczc477hhp7e4VX8HXBn9bB6PN1jmzi62uRaYZmbnmVkm3ufoRedcRbT8t8C50b+bIN5ovw3OuQPJecnSE0pQg5xz7u94f1x/xPsVfRJQ0sXqV+ENYHjazGrxRlq9P1rPM8DngJ/h7XZ5gvd6Mv8FfNLM3jGzm48yvhq8XTs34n1BTcX7Im3o4ik/jJa/CLyEt/uyp+c23Y43cOSAmd3nvMEMy4CP4vUgfwVcFPcl1Zkn8A7kb4hbtj66rD+Gl18EpAOv4I2euxdv8At4PaIddNEDBC7AO664H6/N7uG9dv5d3HNfoW97gu0la9u34Q16eQkox/vxc1troZm9bGYXADjnqvEGcVyP145zifu7cM49ijeg4//wjmOejNfTk35kne+elaEgumurGZjonKtMdTwQi2kn3vGdx1Idz0BiZt8Fqp1zt3W7srf+PXiDVb7ft5GJ9I4GSQxt0/DOX9rT3Yp9KbobcSPeMbBv4e3n789f8IOCc+6IPUkzm4N3LtybeMPTzwH+sx9CE+kVJaghyszOA1YBV7menbfTl+bjHStr3XX18b48ltPXoufLvNJF8dQU9lbH4c2eMAavl/pl59zzR36KSOpoF5+IiPiSBkmIiIgvpWQXX25urisoKEjFpkVEJEXKyspqnHN5PV0/JQmqoKCATZs2pWLTIiKSIma2o/u13qNdfCIi4ktKUCIi4ktKUCIi4ks6D0pEBqWmpiZ27txJOBxOdShDTmZmJuPHjycYDCZUjxKUzzREGqioqaCusY6c9BwKcwvJCGSkOiyRAWfnzp0cc8wxFBQUEHd5Euljzjn279/Pzp07mTRpUkJ1KUH5hHOO9ZXrKS0vpb7pvUv2ZAezKZlWwsIJC/VHJnIUwuGwklMKmBljxoyhuro64bqUoHxifeV6VpetJj+Uz9jhY2PLw5Ewq8tWA7Bo4qKuni4inVBySo1ktbsGSfhAQ6SB0vJS8kP5ZAYy25RlBjLJD+VTWl5KY3Oqp8wTEek/SlA+UFFTQX1TfYfk1CozkMnhpsNsqd7Sz5GJDB2RSIQ9e/ZQWVnJnj17iEQiCdeZlpbGzJkzmTFjBrNnz+Yf//hHr+q55JJLuPfeexOOJ9kef/xxzjrrrD6rX7v4fKCusa77lY5iPRHpOecclZWVlJeX09TUFFseDAaZNm0aEyZM6PUuq6ysLDZv3gzAX//6V6655hqeeOKJZITdY5FIhEBgYH7VqwflAznpOd2vdBTriUjPVVZWUlZWRkZGBiNHjozdMjIyKCsro7IyOVdHqa2tZdSoUQDU1dWxePFiZs+ezSmnnML9998fW+93v/sd06dPZ8aMGVx44YUd6vnXf/1XLrnkElpaWnjwwQcpLCxkwYIFXH755bHezHXXXcfKlSs5/fTTueiii9ixYweLFy9m+vTpLF68OPaa2vfMcnK875jHH3+cD3/4w3zyk5+ksLCQCy64gNYrXzz00EOxbf7pT39KStt0ZWCm1UGmMLeQ7GA24Ui409184UiYrGAWU/KmpCA6kcErEolQXl5OKBTq0MsIBAKEQiHKy8sZP348aWlpR13/4cOHmTlzJuFwmN27d/Poo48C3nlCa9euJRQKUVNTw7x581i2bBmvvPIK119/PU8++SS5ubm8/fbbber79re/zcGDB/ntb39LQ0MDX/ziF1m3bh2TJk3i05/+dJt1y8rK2LBhA1lZWZx99tlcdNFFXHzxxdxxxx1cfvnl3HfffUeM/fnnn+fll1/m+OOP57TTTuPJJ5+kuLiYFStW8Oijj3LyySezfPnyo26To6EelA9kBDIomVZCVW0V4UjbkwrDkTBVtVWUTCshPS09RRGKDE41NTU0NTV1uQssEAjQ1NTU6yHTrbv4KioqeOihh7joootwzuGc4zvf+Q7Tp09nyZIlVFVVsXfvXh599FE++clPkpubC8Do0aNjdf37v/87Bw4c4LbbbsPMqKio4MQTT4yda9Q+QS1btoysrCwAnnrqKT7zmc8AcOGFF7Jhw4ZuYz/11FMZP348w4YNY+bMmWzfvp2KigomTZrE5MmTMTM++9nP9qpdeko9KJ9YOGEhAKXlpeyt2xtbnhXMYkXRili5iCRPY2PPRsb2dL0jmT9/PjU1NVRXV/Pggw9SXV1NWVkZwWCQgoICwuEwzrkuj3fNmTOHsrIy3n77bUaPHk13F5sdPnx4l2Wt2wgEArS0tADesbj415mR8d4EAWlpabFBI/05dF8JyifMjEUTFzE3f26bmSSm5E1Rz0mkj6Sn9+xvq6frHUlFRQXNzc2MGTOGgwcPMnbsWILBII899hg7dnhXoVi8eDHnnnsuV1xxBWPGjIklI4ClS5dyxhln8LGPfYyHH36YwsJC3njjDbZv305BQQH33HNPl9v+4Ac/SGlpKRdeeCF33303CxYsALxLH5WVlfGpT32K+++/v80gkc4UFhby5ptvsm3bNk466STWrFmTcLsciRKUz2QEMpgxbkaqwxAZEnJzcwkGg12OdItEIgSDQfLyenyNvTZaj0GB10O56667SEtL44ILLuDss8+muLiYmTNnUlhYCMAHPvABrr32Wj70oQ+RlpbGrFmzuPPOO2P1nX/++Rw6dIhly5bx4IMP8qtf/YqlS5eSm5vLqaee2mUcN998M5///Oe56aabyMvL47e//S0AK1as4JxzzuHUU09l8eLFR+x1gXfsbNWqVXzsYx8jNzeXBQsWUF5e3qu26QnrrpvYF4qLi50uWCgifWnLli1MmdL9wKIdO3ZQVlbWYaBEJBKhtraWoqIiJk6c2Jeh9lpdXR05OTk45/jqV7/K5MmTueKKK1IdFtB5+5tZmXOuuKd1qAclIkPahAkTACgvL6eu7r1zDYPBIEVFRbFyP1q9ejV33XUXjY2NzJo1iy9+8YupDimplKBEZEgzMyZOnEh+fj41NTU0NjaSnp5OXl5er4aW96crrrjCNz2mvqAEJSKCN6Jt3LhxqQ5D4ug8KBER8SUlKBER8aWkJSgzSzOz583sf5NVp4iIDF3JPAb1dWALEEpinSIi/aIh0tDmJPnC3EIyAhndP/EI0tLSOOWUU2LTKV188cV84xvfYNgwf++8uu6668jJyeGb3/xmSuNISoIys/HAx4DrgSuTUaeISH9wzrG+cj2l5aXUN9XHlmcHsymZVsLCCQuTcrmNffv28ZnPfIaDBw/ygx/8IBmhD3rJSuM/B74NtCSpPhGRfrG+cj2ry1YTyghRMLIgdgtlhFhdtpr1leuTsp2xY8eyatUqbrnlFpxzNDc3861vfYs5c+Ywffp0brvttti6N954I6eccgozZszg6quvBmDbtm0sXbqUoqIiFi5cSEVFBQAPPPAAc+fOZdasWSxZsoS9e725PJ944glmzpzJzJkzmTVrFocOHQLgpptuim3z+9//fmyb119/Pe9///tZsmQJr776alJec6IS7kGZ2VnAPudcmZl9+AjrrQRWAr4+8U1Eho6GSAOl5aXkh/I7XOomM5BJfiif0vJS5o2fl5Q5MU888URaWlrYt28f999/PyNGjODZZ5+loaGB0047jdNPP52Kigruu+8+Nm7cSHZ2duySGytXruTWW29l8uTJbNy4ka985Ss8+uijLFiwgKeffhoz4ze/+Q033ngjP/nJT/jxj3/ML3/5S0477TTq6urIzMzk4YcfZuvWrTzzzDM451i2bBnr1q1j+PDhlJaW8vzzzxOJRJg9ezZFRUUJv95EJWMX32nAMjM7E8gEQmb2e+dcm3nYnXOrgFXgTXWUhO2KiCSkoqaC+qZ6xg4f22l5ZiCTvXV72VK9JWlzZLZOL/fwww/z4osvxi4YePDgQbZu3cojjzzC5z73ObKzswHvkht1dXX84x//4Pzzz4/V09DQAMDOnTtZvnw5u3fvprGxMXb5jdNOO40rr7ySCy64gE984hOMHz+ehx9+mIcffphZs2YB3lRJW7du5dChQ5x77rmxbS5btiwprzVRCe/ic85d45wb75wrAEqAR9snJxERP6prrOt+paNYrztvvPEGaWlpjB07Fuccv/jFL9i8eTObN2/mzTff5PTTT+/0khstLS2MHDkytu7mzZvZsmULAF/72te47LLLeOmll7jtttsIh71ryl199dX85je/4fDhw8ybN4+Kigqcc1xzzTWxOl5//XW+8IUvAP17GY2e8vdQEhGRPpSTnpPU9Y6kurqaL33pS1x22WWYGWeccQa//vWvY5e4eO2113j33Xc5/fTTueOOO6iv9wZsvP3224RCISZNmsQf/vAHwOuFvfDCC4DX88rPzwfgrrvuim1v27ZtnHLKKVx11VUUFxdTUVHBGWecwR133BGbc7Cqqop9+/axaNEi1q5dy+HDhzl06BAPPPBAwq83GZI61ZFz7nHg8WTWKSLSVwpzC8kOZhOOhDscgwLvitZZwSym5HU/K3pnWi+30TrM/MILL+TKK72Bzpdeeinbt29n9uzZOOfIy8vjvvvuY+nSpWzevJni4mLS09M588wzueGGG7j77rv58pe/zA9/+EOampooKSlhxowZXHfddZx//vnk5+czb9483nzzTQB+/vOf89hjj5GWlsbUqVP56Ec/SkZGBlu2bGH+/PkA5OTk8Pvf/57Zs2ezfPlyZs6cycSJE1m40B8XSNXlNkRkUOrp5TbW7VjH6rLVHQZKhCNhqmqrWFG0gkUTF/VlqIOSLrchIpKghRO83kJpeSl76/bGlmcFs1hRtCJWLv1PCUpEhjQzY9HERczNn9tmJokpeVOSMrRcek8JSkQEyAhkJG0ouSSHElQ/6Is5vkREBjslqD7Ul3N8iYgMdkpQfah1jq/8UH6bM9XDkTCry1YDaHSQiEgXdKJuH+npHF+NzY0pilBE2mhugHdegOonvf+bG5JW9dq1azGz2ASv27dvZ9q0aQBs2rSJyy+/PGnbGkzUg+ojqZjjS0R6wTmoXg/bS6H5vV3xpGVDQQnkLYQEd8WvWbOGBQsWUFpaynXXXdemrLi4mOLiHp8aNKSoB9VH+nuOLxHpper18PpqCIZgeMF7t2DIW16d2OU26urqePLJJ7n99tspLS3tUP74449z1lln0dLSQkFBAQcOHIiVnXzyyezdu5fq6mrOO+885syZw5w5c3jyyScTimmgUILqI/05x5eI9FJzg9dzysqHtHZTHaVlesu3l0ICu+Jbpy963/vex+jRo3nuuec6XW/YsGGcc845rF27FoCNGzdSUFDAsccey9e//nWuuOIKnn32Wf74xz9y6aWX9jqegUQJqo/Ez/HVmUTn+BKRJKit8HbrtU9OrdIyofkw1G7p9SbWrFlDSUkJACUlJaxZs6bLdZcvX84999wDQGlpKcuXLwfgkUce4bLLLmPmzJksW7aM2tra2AUIBzMdg+ojGYEMSqaVdDvHl85UF0mhSA92sVsP1+vE/v37efTRRykvL8fMaG5uxsz4yle+0un68+fP5/XXX6e6upr77ruP7373u4B3uY2nnnqKrKysXsUxUKkH1YcWTljIiqIV1DbUsuPAjtittqFWc3yJ+EGgB7vYXQ/X68S9997LRRddxI4dO9i+fTtvvfUWkyZNYufOnZ2ub2ace+65XHnllUyZMoUxY8YAcPrpp3PLLbfE1tu8eXOv4hlo1IPqQ5rjS8TnQoXeaL3mcOe7+ZrDkJYFod7til+zZg1XX311m2XnnXceN9xwQ5fPWb58OXPmzOHOO++MLbv55pv56le/yvTp04lEIixatIhbb721VzENJLrchogMSj293Ab71nmj9doPlGgOw+EqOHkFjNUJ9UdLl9sQEUlUXnRX+/ZSCO/1jjk5vJ7TySveK5d+pwQlIkObmddDGjPXG9UXqfOOOYWmgHbFp5QSlIgMWs65nk/InJYBozSrSzIk69CRRvGJyKCUmZnJ/v37k/ZlKT3jnGP//v1kZnZxbtlRUA9KRAal8ePHs3PnTqqrq1MdypCTmZnJ+PHjE65HCUpEBqVgMMikSZNSHYYkIOFdfGZ2gpk9ZmZbzOxlM/t6MgITEZGhLRk9qAjwL86558zsGKDMzP7mnHslCXWLiMgQlXAPyjm32zn3XPT+IWALkJ9ovSIiMrQldRSfmRUAs4CNnZStNLNNZrZJBy1FRKQ7SUtQZpYD/BH4hnOutn25c26Vc67YOVecl5eXrM2KiMgglZQEZWZBvOR0t3PuT8moU0REhrZkjOIz4HZgi3Pup4mHJCIikpwe1GnAhcBHzGxz9HZmEuoVEZEhLOFh5s65DXjz/0o/aIg0tLm2VGFuIRmBjFSHJSKSdJpJYoBwzrG+cj2l5aXUN9XHlmcHsymZVsLCCQt7PimmiMgAoAQ1QKyvXM/qstXkh/IZO3xsbHk4EmZ12WoAFk3URdVEZPDQbOYDQEOkgdLyUvJD+WQG2s4QnBnIJD+UT2l5KY3NjSmKUEQk+ZSgBoCKmgrqm+o7JKdWmYFMDjcdZkv1ln6OTESk7yhBDQB1jXVJXU9EZCDQMagBICc9J3Y/0hKhpr6GxuZG0tPSyc3OJTAs0GE9EZGBTgkqhXo6ZLwwt5CsQBav7X+Nrfu30tTSFCsLDgsyecxkRmSMYErelP4MX0SkTylBpcDRDhnPCGQwNW8qP3vqZ4zNGcvw9OGxsnAkzNNvPc0V868gPS29X1+HiEhfUoJKga6GjNc11nHjhht5afJLLJiwINajaog08Er1K8w/YT6v7X+NA+EDsecEhwWZf8J8Xql+JbbbT0RkMFCC6medDRl3zlF5sJLyfeWEm8P8YuMv2Fi1kZz0HEqmlRBKD3E4cpjJYyYzadSkNseg8rLzSBuWxo4DO9hSvYUZ42ak+BWKiCSHElQ/ax0yHt9zqjxYSdnuMkIZIYanD+dA+ADZwWxCGSFWl61m3vh5sXUDwwKMyxnXad0axScig4mGmfez9kkk0hKhfF85oYxQbDQeQGNzY+wk3Cd2PEFzS3O3dWsUn4gMJkpQ/ax9Eqmpr6GppalNcgJix5IyA5lkBjJpaG4gHAl3Wmc4EiYrmKVRfCIyqChB9bPC3EKyg9mxZNN+eqJIS4TgsCB52XlEWiLsqdvD/vr9nDTqJCoPVHZIUuFImKraKkqmlWiAhIgMKjoG1Ye6Os+pZFpJbBRffFKJtESobahl9nGz2Vm7k/J95TS1NFHXWEeapTFs2DAqaioYmTEyNgw9K5jFiqIVLJywMFUvU0SkTyhB9YHuznNacMICAK+8sZ5wJMz++v1kBjIpOq4IIDZoIoMMgsOCzBg3g6aWJioPVrKoYBHvH/N+ctJzmJI3RT0nERmUlKD6QE8vjTE3fy4VNRVsqNzAg1sfZGreVDICGfz19b8SyggBUNtQS9FxRaQNSyNtWBoTRkxg065NfHb6Z5WYRGRQ0zGoJDuaS2NkBDKYMW4GX5nzFa5acBXvNr3LS3tf4p3wO9Q11tEQaaDouCImjJjQpg7NXC4iQ4F6UEnW2XlO8TIDmeyt29vmpFozi/Wo1pSvoamliQkjJsROwu2MznkSkcHOnHP9vtHi4mK3adOmft8uAM0NUFsBkToI5MDwSfDum20fH3gJKtdC9TrvOYEc73bgZTi8GzjcZfWRowil/a+DSGdPPsJPiG5/XUy8BI6ZBJl5EMiC0Adg1HRI6zghba+1b89QYdv6uytPxjZEpEuRSISamhoaGxtJT08nNzeXQCA1fRMzK3POFfd0/aHTg3IOqtfD9lJojg5cCO+Fd9+C7PGQMRYO74V3NkNTDdDSq830Zp9pS3RTwzp7cmsYval4x53v3Q+OgYzRMGIqFF4BYxdB3IS0R62z9gRIy4aCEshdADUbui7PW9j99rvbRk/qEBminHNUVlZSXl5OU1PcFRCCQaZNm8aECRPaTErtR0lJUGa2FPgvIA34jXPuP5NRb1JVr4fXV0NWPmSOhXd3QH2V94v88C7A4OBL0LQvoc305u3uzWfkqJ8SOQjBY+DQVii/Hk4xL0n1Vvv2bNUc9pa/8wLsf6brcuh++91toyd1iAxRlZWVlJWVEQqFGD78vSsgRCIRysrKAJg4cWKqwuuRhAdJmFka8Evgo8BU4NNmNjXRepOqucH7FZ6VD2mZ4CJwoByCIe9xWg7sfxYa3k54Uz1NHK3r9XgPa6J7Yl2z12MMhKChGt68G9qdJNxj7dszXlomZBwLW2+DzHGdl2flR3tFR9h+d9voSR0iQ1QkEqG8vJxQKNRhd14gECAUClFeXk5zc/dTqKVSwsegzGw+cJ1z7ozo42sAnHP/0dVzknEMavltT3VYdtb047hwfgGHG5u55LfPvFcQqYP6nXxych3nn7iftw++zZc3TAaLvnGuGZrr+ezo/+PskevY1ZjLFW/9S4f6V+StZUnoGbaF8/lO1WUdyr82tpQFx7zAy4cn8W+7VnYo/9a4uygaXkHZu4XctOfiDuXfO24VU7PeZEPdDG7ZV9Kh/Pr8Wzg5s4pHak9ldfW5Hcp/dsJPOD69hgcOLOT3+8/sUP7rgh8zeuRY/lA9l3urPwg5BV4PMurOz51KVnoa//3Udv73xd0dnn/PF+cDsOqhDfz9pa1tEkdmWgt3/dNWAG5+/hierEqD9FEwzBsKPyojwq0LtwHwo83jeW5vALLzY9s/bkQmPy+ZBcAPHniZVyp3Qf3O2DZOPCbMf8zdAcA1GyfyxqFML4lF65h6fIjvn/0BAL5R+jy7D7adcWP2xFFctbQQgC/9dxnv1LdNbKednMvliycDcPEdzxBuavuHu3jKWFYuOgk4ys9e1CeLxnN+8Qm8/W4jX/59WYfyz86byNkzjmfXgcNccc/mDuUrFp7IkqnHsq26ju/86aUO5V/7yGQWTM7l5V0H+bcHXulQ/u2l76do4mjKdrzNjQ+92qH8e2dP5QPHj2DD1hp+8ejWDuU3fOIUTsrL4ZFX9rJ6/Rsdyn+2fCbHj8zigRd28fund3Qo//Vnixg9PJ0/bHqLe8t2dijv8Wdv3Tb+vqXtXo7MYBp3ff5UAG7++1aefL2mTfmo7HRuvdA7v/BHD1Xw3I532pR3+Oztqm1TfmLecP7jE9MBuOZPL/JG9bttyv342WtsbKS2tpZAIMCC/AALxwc51Oi45fn3YotEIoRCIT6/aHKPPnvJcLTHoJIxzDwfeCvu8c7osvaBrTSzTWa2qbq6OgmbPQqu3a+Elk5+dbvYP33K6N1uwNbnJsy17ot2Hdulp1oautlGtN7ufvwcafs9ja23r0FkEOtpxyMVg+SORjJ6UOcDZzjnLo0+vhA41Tn3ta6e0++j+N55ASp+BsMLvMfhPVDzNARHeo8jdVC7xTu20cvBEb11NM2f8PFMS4eckyAtHbInwox/g1G9uH5U+/Zs7/Ae2PsIjFvi7ebrzLs7oPAbXW+/u230pA6RIWrPnj08/fTTjBw5sst1Dhw4wLx58xg3rou/0T6Qih7UTuCEuMfjgV1JqDd5QoXeyK/maPc2Ixcs6B2LAu+Le1gWEExZiH3PwNIgOMK7nzUOQr2c/bx9e7YXyIFhmRA4pvPy5jCkZR15+91toyd1iAxRubm5BINBIp2eu+Lt3gsGg+Tl5fVzZEcnGQnqWWCymU0ys3SgBPhzEupNnrQMb1jy4Srvi80CMHIaNNV6j5vrYMwcbxh2P+tpryjx3lMaZB4LkVrIyINJF3g9qd5o357xmsPQsBcmf9HrqXZWfrjKe/6Rtt/dNnpSh8gQFQgEmDZtGrW1tR2SVCQSoba2lmnTppGW1vlEAH6R8DBz51zEzC4D/oo3zPwO59zLCUeWbHnR2b63l3qj2XDeAfZ334LsE7xhzCNOgXeaEzoPqjd6spvPWYK/JgIjvAELx0z2zoPKS3D28/btaXiH8NKy4OQV3nlQo2Z0Xd6T7Xe3jURfg8ggNmGCN0VaeXk5dXXvzTwTDAYpKiqKlfuZZpIYfiK8+0bbxwdebDuTRPAYbyj6gfJuZ5JIRE9mkkjjKAZLTPycN5NE1livRzJiGoycntxeR4dZHqa0rb+78mRsQ0S61H4miby8vJT1nI72GNTQS1A+t27HuthM6K2TzUZaIuw6tIuq2iqWT1vOBadcQEZAU/2IyMCiqY4GsPYzoTvnqDxYGbtwYXNLMzc+eSMbd27kgukXsHDCQt9PVSIi0lu63IaPtM6E3tpzqjxYSdnuMjICGYzMHMmY7DFkBjJpbG5kddlq1leuT3HEIiJ9Rz0oH4m/hEakJUL5vnJCGSECw9q+TWbGsTnHcsszt9DiWhiVOSp2OXkRkcFCCcpHctLfm3aopr6GppYmhg8b3mYd5xz76/fHLmz406d+yuis0bHLyWu3n4gMFtrF5yOFuYVkB7MJR8I0djIJaqQlQkOkgTfeeYOMQAY56TnkZudSMLKAUEZIu/1EZFBRgvKRjEAGJdNKqKqt6lAWaYlwIHwADEZkjojt9kuPDrdufzl5EZGBTgnKZxZOWMiKohUEhwUJR8Lsr9/PgfABGiINnDTqJDLSMggMCxBpiRAcFiQv+72pSjIDmRxuOsyW6i0pfAUiIsmhY1A+Y2bMzZ9LViCL0VmjeWLHE5w86mQmjpxI1aEqdhzcQaQlQm1DLUXHFZE2rOMJd/GDLUREBiolKB9xzrG+cj2l5aXUN9XjnCOUEeK5Pc9RXV9NMC1IXWMdwWFBio4rYsKIzqcqiR9sISIyUClB+cj6yvWxWSTGDvcucT5p1CTqGuuoqK7gIwUfITOQycQRExmePrzD88ORMFnBLKbkaYZvERn4dAzKJ9rPIhEvJz2HacdO47W3X+NLxV9iT90ewpG2M3yHI2GqaqsomVYSGzghIjKQKUH5RPtZJNprHQAxOnM0K4pWUNtQy44DO2K32oZaVhStYOEEzfAtIoODdvH5RE8HNrzb9C6LJi5ibv5cKmoqqGusIyc9hyl5U9RzEpFBRQnKJ3o6sKF1vYxABjPG6VLnIjJ4aRefT8TPItEZDYAQkaFGCcon4meR0AAIERHt4vOV1gEOpeWl7K3bG1ueFczSAAgRGXKUoHzEzDQAQkQkSgnKhzQAQkREx6BERMSnEkpQZnaTmVWY2YtmttbMRiYpLhERGeIS7UH9DZjmnJsOvAZck3hIIiIiCSYo59zDzrlI9OHTwPjEQxIREUnuMajPA3/pqtDMVprZJjPbVF1dncTNiojIYNTtKD4zewQY10nRtc65+6PrXAtEgLu7qsc5twpYBVBcXOx6Fa2IiAwZ3SYo59ySI5Wb2cXAWcBi55wSj4iIJEVC50GZ2VLgKuBDzrn65IQkIiKS+DGoW4BjgL+Z2WYzuzUJMYmIiCTWg3LOnZysQEREROJpJgkREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfElJSgREfGlpCQoM/ummTkzy01GfSIiIgknKDM7AfhnoDLxcERERDzJ6EH9DPg24JJQl4iICJBggjKzZUCVc+6FHqy70sw2mdmm6urqRDYrIiJDQKC7FczsEWBcJ0XXAt8BTu/Jhpxzq4BVAMXFxeptiYjIEXWboJxzSzpbbmanAJOAF8wMYDzwnJmd6pzbk9QoRURkyOk2QXXFOfcSMLb1sZltB4qdczVJiEtERIY4nQclIiK+1OseVHvOuYJk1SUiIqIelIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+JISlIiI+FLCCcrMvmZmr5rZy2Z2YzKCEhERCSTyZDP7J+AcYLpzrsHMxiYnLBERGeoS7UF9GfhP51wDgHNuX+IhiYiIJJ6g3gcsNLONZvaEmc3pakUzW2lmm8xsU3V1dYKbFRGRwa7bXXxm9ggwrpOia6PPHwXMA+YA/8/MTnTOufYrO+dWAasAiouLO5SLiIjE6zZBOeeWdFVmZl8G/hRNSM+YWQuQC6iLJCIiCUl0F999wEcAzOx9QDpQk2CdIiIiiY3iA+4A7jCzcqARuLiz3XsiIiJHK6EE5ZxrBD6bpFhERERiNJOEiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4khKUiIj4UkIJysxmmtnTZrbZzDaZ2anJCkxERIa2RHtQNwI/cM7NBL4XfSwiIpKwRBOUA0LR+yOAXQnWJyIiAkAgwed/A/irmf0YL9l9sKsVzWwlsBJgwoQJCW5WREQGu24TlJk9AozrpOhaYDFwhXPuj2b2KeB2YEln9TjnVgGrAIqLi12vIxYRkSGh2wTlnOs04QCY2e+Ar0cf/gH4TZLiEhGRIS7RY1C7gA9F738E2JpgfSIiIkDix6BWAP9lZgEgTPQYk4iISKISSlDOuQ1AUZJiERERidFMEiIi4ktKUCIi4ktKUCIi4ktKUCIi4kuJjuKTOA2RBipqKqhrrCMnPYfC3EIyAhmpDktEZEBSgkoC5xzrK9dTWl5KfVN9bHl2MJuSaSUsnLAQM0thhCIiA48SVBKsr1zP6rLV5IfyGTt8bGx5OBJmddlqABZNXJSq8EREBiQdg0pQQ6SB0vJS8kP5ZAYy25RlBjLJD+VTWl5KY3NjiiIUERmYlKASVFFTQX1TfYfk1CozkMnhpsNsqd7Sz5GJiAxsSlAJqmusS+p6IiLiUYJKUE56TlLXExERjxJUggpzC8kOZhOOhDstD0fCZAWzmJI3pZ8jExEZ2JSgEpQRyKBkWglVtVUdklQ4EqaqtoqSaSWkp6WnKEIRkYFJw8yTYOGEhQCUlpeyt25vbHlWMIsVRSti5SIi0nNKUElgZiyauIi5+XPbzCQxJW+Kek4iIr2kBJVEGYEMZoybkeowREQGBR2DEhERX1KCEhERX1KCEhERX1KCEhERXzLnXP9v1Kwa2NGPm8wFavpxe4lSvH1rIMU7kGIFxdvXBlK8ncU60TmX19MKUpKg+puZbXLOFac6jp5SvH1rIMU7kGIFxdvXBlK8yYhVu/hERMSXlKBERMSXhkqCWpXqAI6S4u1bAynegRQrKN6+NpDiTTjWIXEMSkREBp6h0oMSEZEBRglKRER8aVAnKDO7ycwqzOxFM1trZiOjywvM7LCZbY7ebk1xqDFmttTMXjWz183s6lTHE8/MTjCzx8xsi5m9bGZfjy6/zsyq4trzzFTH2srMtpvZS9G4NkWXjTazv5nZ1uj/o1IdJ4CZvT+uDTebWa2ZfcNP7Wtmd5jZPjMrj1vWZXua2TXRz/KrZnaGT+L15fdCF7F2+d77tG3viYt1u5ltji7vXds65wbtDTgdCETv/wj4UfR+AVCe6vg6iTcN2AacCKQDLwBTUx1XXHzHAbOj948BXgOmAtcB30x1fF3EvB3IbbfsRuDq6P2rWz8XfrpFPwt7gIl+al9gETA7/u+nq/aMfjZeADKASdHPdpoP4vXl90IXsXb63vu1bduV/wT4XiJtO6h7UM65h51zkejDp4HxqYynB04FXnfOveGcawRKgXNSHFOMc263c+656P1DwBYgP7VR9co5wF3R+3cBH09dKF1aDGxzzvXnjCvdcs6tA95ut7ir9jwHKHXONTjn3gRex/uM95vO4vXr90IXbdsVX7ZtKzMz4FPAmkS2MagTVDufB/4S93iSmT1vZk+YmV8ueZsPvBX3eCc+TQBmVgDMAjZGF10W3WVyh192mUU54GEzKzOzldFlxzrndoOXdIGxKYuuayW0/eP2a/tC1+05ED7PA+F7obP33u9tuxDY65zbGrfsqNt2wCcoM3vEzMo7uZ0Tt861QAS4O7poNzDBOTcLuBL4HzML9X/0HVgny3x3HoCZ5QB/BL7hnKsFfg2cBMzEa9ufpC66Dk5zzs0GPgp81cwWpTqg7phZOrAM+EN0kZ/b90h8/XkeIN8LXb33vm5b4NO0/YHVq7Yd8FfUdc4tOVK5mV0MnAUsdtGdoc65BqAher/MzLYB7wM29XG43dkJnBD3eDywK0WxdMrMgnjJ6W7n3J8AnHN748pXA/+bovA6cM7tiv6/z8zW4u0G2WtmxznndpvZccC+lAbZ0UeB51rb1c/tG9VVe/r28zxQvheO8N77uW0DwCeAotZlvW3bAd+DOhIzWwpcBSxzztXHLc8zs7To/ROBycAbqYmyjWeByWY2KforugT4c4pjionuV74d2OKc+2nc8uPiVjsXKG//3FQws+FmdkzrfbyD4+V4bXpxdLWLgftTE2GX2vz69Gv7xumqPf8MlJhZhplNwvs7eyYF8bUxkL4XjvDe+7Jto5YAFc65na0Let22/Tnqo79veAcO3wI2R2+3RpefB7yMNwrmOeDsVMcaF/OZeKPjtgHXpjqedrEtwNuN8GJcm54J/DfwUnT5n4HjUh1rNN4To+/xC9H3+9ro8jHA34Gt0f9HpzrWuJizgf3AiLhlvmlfvMS5G2jC+xX/hSO1J3Bt9LP8KvBRn8Try++FLmLt8r33Y9tGl98JfKndur1qW011JCIivjSod/GJiMjApQQlIiK+pAQlIiK+pAQlIiK+pAQlIiK+pAQlIiK+pAQlIiK+9P8B4xPkc98LbZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = foreground_norm\n",
    "Y = background_norm\n",
    "X, Y = X.T, Y.T\n",
    "gamma = 0.06\n",
    "k = 2\n",
    "#plt.figure(figsize=(len(gamma_range) * 7, 5))\n",
    "\n",
    "pcpca = PCPCA(gamma=gamma, n_components=k)\n",
    "X_proj, Y_proj = pcpca.fit_transform(X, Y)\n",
    "plt.title(\"Projecting onto W_mle, gamma=\" + str(gamma))\n",
    "plt.scatter(Y[0, :], Y[1, :], alpha=0.5, label=\"Background\", s=80, color=\"gray\")\n",
    "plt.scatter(X_proj[0, :13], X_proj[1, :13], alpha=0.5, label=\"Deceased\", s=80, color=\"green\")\n",
    "plt.scatter(X_proj[0, 13:], X[1, 13:], alpha=0.5, label=\"Alive\", s=80, color=\"orange\")\n",
    "\n",
    "origin = np.array([[0], [0]])  # origin point\n",
    "# This is the line that distinguishes between the two classes.\n",
    "abline(slope=pcpca.W_mle[1, 0] / pcpca.W_mle[0, 0], intercept=0)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
