{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCPCA Implementation from: https://arxiv.org/abs/2012.07977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "inv = np.linalg.inv\n",
    "slogdet = np.linalg.slogdet\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCPCA:\n",
    "\n",
    "    def __init__(self, n_components=2, gamma=0.5):\n",
    "        \"\"\"Initialize PCPCA model.\n",
    "        \"\"\"\n",
    "        self.k = n_components\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Fit model via maximum likelihood estimation.\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == Y.shape[0]  # Should have same number of features\n",
    "        p, n, m = X.shape[0], X.shape[1], Y.shape[1]\n",
    "\n",
    "        # Get sample covariance\n",
    "        Cx, Cy = self._compute_sample_covariance(\n",
    "            X), self._compute_sample_covariance(Y)\n",
    "\n",
    "        # Differential covariance\n",
    "        Cdiff = n * Cx - self.gamma * m * Cy\n",
    "\n",
    "        # Eigendecomposition\n",
    "        eigvals, U = np.linalg.eigh(Cdiff)\n",
    "\n",
    "        # Sort by eigenvalues and truncate to number of components\n",
    "        sorted_idx = np.argsort(-eigvals)\n",
    "        eigvals = eigvals[sorted_idx]\n",
    "        U = U[:, sorted_idx]\n",
    "        Lambda = np.diag(eigvals)\n",
    "        Lambda, U = Lambda[:self.k, :self.k], U[:, :self.k]\n",
    "\n",
    "        # MLE for sigma2\n",
    "        sigma2_mle = 1 / (p - self.k) * \\\n",
    "            np.sum(eigvals[self.k:] / (n - self.gamma * m))\n",
    "\n",
    "        # MLE for W\n",
    "        Lambda_scaled = Lambda / (n - self.gamma * m)\n",
    "        W_mle = U @ sqrtm(Lambda_scaled - sigma2_mle * np.eye(self.k))\n",
    "\n",
    "        self.sigma2_mle = sigma2_mle\n",
    "        self.W_mle = W_mle\n",
    "\n",
    "    def transform(self, X, Y):\n",
    "        \"\"\"Embed data using fitted model.\n",
    "        \"\"\"\n",
    "        \n",
    "        t = self.W_mle.T @ X, self.W_mle.T @ Y\n",
    "        return t\n",
    "\n",
    "    def fit_transform(self, X, Y):\n",
    "        self.fit(X, Y)\n",
    "        t = self.transform(X, Y)\n",
    "        return t\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Sample from the fitted model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_gamma_bound(self, X, Y):\n",
    "        \"\"\"Compute the upper bound on gamma such that sigma2 > 0.\n",
    "        \"\"\"\n",
    "        p = X.shape[0]\n",
    "        Cx = self._compute_sample_covariance(X)\n",
    "        Cy = self._compute_sample_covariance(Y)\n",
    "        Cx_eigvals = -np.sort(-np.linalg.eigvals(Cx))\n",
    "        Cy_eigvals = -np.sort(-np.linalg.eigvals(Cy))\n",
    "\n",
    "        gamma_bound = np.sum(Cx_eigvals[self.k-1:]) / \\\n",
    "            ((p - self.k) * Cy_eigvals[0])\n",
    "        return gamma_bound\n",
    "\n",
    "    def _compute_sample_covariance(self, data):\n",
    "        \"\"\"Compute sample covariance where data is a p x n matrix.\n",
    "        \"\"\"\n",
    "        n = data.shape[1]\n",
    "        cov = 1 / n * data @ data.T\n",
    "        return cov\n",
    "\n",
    "    # Indication matrix for observed values\n",
    "    def make_L(self, X):\n",
    "        p = X.shape[0]\n",
    "        unobserved_idx = np.where(np.isnan(X))[0]\n",
    "        observed_idx = np.setdiff1d(np.arange(p), unobserved_idx)\n",
    "        L = np.zeros((observed_idx.shape[0], p))\n",
    "        for ii, idx in enumerate(observed_idx):\n",
    "            L[ii, idx] = 1\n",
    "        return L\n",
    "\n",
    "    # Indication matrix for unobserved values\n",
    "    def make_P(self, X):\n",
    "        p = X.shape[0]\n",
    "        unobserved_idx = np.where(np.isnan(X))[0]\n",
    "        P = np.zeros((unobserved_idx.shape[0], p))\n",
    "        for ii, idx in enumerate(unobserved_idx):\n",
    "            P[ii, idx] = 1\n",
    "        return P\n",
    "\n",
    "    def impute_missing_data(self, X):\n",
    "        p, n = X.shape\n",
    "        W, sigma2 = self.W_mle, self.sigma2_mle\n",
    "\n",
    "        # Indication matrices for observed values\n",
    "        Ls = [self.make_L(X[:, ii]) for ii in range(n)]\n",
    "\n",
    "        # Indication matrices for unobserved values\n",
    "        Ps = [self.make_P(X[:, ii]) for ii in range(n)]\n",
    "\n",
    "        # Cov between observed features\n",
    "        As = [Ls[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "\n",
    "        # Cov between unobserved features\n",
    "        Cs = [Ps[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ps[ii].T for ii in range(n)]\n",
    "\n",
    "        # Cov between unobserved/observed features\n",
    "        Fs = [Ps[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "\n",
    "        # Find conditional mean of unobserved values\n",
    "        X_imputed = X.copy()\n",
    "        for ii in range(n):\n",
    "            unobserved_idx = np.where(np.isnan(X[:, ii]))[0]\n",
    "            observed_idx = np.setdiff1d(np.arange(p), unobserved_idx)\n",
    "            xhat_u_ii = Fs[ii] @ inv(As[ii]) @ X_imputed[:, ii][observed_idx]\n",
    "            X_imputed[unobserved_idx, ii] = xhat_u_ii\n",
    "\n",
    "        return X_imputed\n",
    "\n",
    "\n",
    "    def gradient_descent_missing_data(self, X, Y, n_iter=500, verbose=True):\n",
    "\n",
    "        def grads(X, Y, W, sigma2, gamma):\n",
    "            p, n = X.shape\n",
    "            m = Y.shape[1]\n",
    "\n",
    "            # Indication matrices\n",
    "            Ls = [self.make_L(X[:, ii]) for ii in range(n)]\n",
    "            Ms = [self.make_L(Y[:, ii]) for ii in range(m)]\n",
    "\n",
    "            As = [Ls[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "            Bs = [Ms[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ms[ii].T for ii in range(m)]\n",
    "\n",
    "            running_sum_W_X = np.zeros((p, p))\n",
    "            running_sum_sigma2_X = 0\n",
    "            for ii in range(n):\n",
    "                L, A = Ls[ii], As[ii]\n",
    "                x = L @ np.nan_to_num(X[:, ii], nan=0)\n",
    "                Di = L.shape[0]\n",
    "                A_inv = inv(A)\n",
    "\n",
    "                curr_summand_W = L.T @ A_inv @ (np.eye(Di) - np.outer(x, x) @ A_inv) @ L\n",
    "                running_sum_W_X += curr_summand_W\n",
    "\n",
    "                curr_summand_sigma2 = np.trace(A_inv @ L @ L.T) - np.trace(A_inv @ np.outer(x, x) @ A_inv @ L @ L.T)\n",
    "                running_sum_sigma2_X += curr_summand_sigma2\n",
    "\n",
    "            running_sum_W_Y = np.zeros((p, p))\n",
    "            running_sum_sigma2_Y = 0\n",
    "            for jj in range(m):\n",
    "                M, B = Ms[jj], Bs[jj]\n",
    "                y = M @ np.nan_to_num(Y[:, jj], nan=0)\n",
    "                Ej = M.shape[0]\n",
    "                B_inv = inv(B)\n",
    "\n",
    "                curr_summand_W = M.T @ B_inv @ (np.eye(Ej) - np.outer(y, y) @ B_inv) @ M\n",
    "                running_sum_W_Y += curr_summand_W\n",
    "\n",
    "                curr_summand_sigma2 = np.trace(B_inv @ M @ M.T) - np.trace(B_inv @ np.outer(y, y) @ B_inv @ M @ M.T)\n",
    "                running_sum_sigma2_Y += curr_summand_sigma2\n",
    "\n",
    "            W_grad = -(running_sum_W_X - gamma * running_sum_W_Y) @ W\n",
    "            sigma2_grad = -0.5 * running_sum_sigma2_X + gamma/2.0 * running_sum_sigma2_Y\n",
    "\n",
    "            return W_grad, sigma2_grad\n",
    "\n",
    "        def log_likelihood(X, Y, W, sigma2, gamma):\n",
    "            p, n = X.shape\n",
    "            m = Y.shape[1]\n",
    "            Ls = [self.make_L(X[:, ii]) for ii in range(n)]\n",
    "            Ms = [self.make_L(Y[:, ii]) for ii in range(m)]\n",
    "\n",
    "            As = [Ls[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ls[ii].T for ii in range(n)]\n",
    "            Bs = [Ms[ii] @ (W @ W.T + sigma2 * np.eye(p)) @ Ms[ii].T for ii in range(m)]\n",
    "\n",
    "            running_sum_X = 0\n",
    "            for ii in range(n):\n",
    "                L = Ls[ii]\n",
    "                A = As[ii]\n",
    "                x = L @ np.nan_to_num(X[:, ii], nan=0)\n",
    "                Di = L.shape[0]\n",
    "                A_inv = inv(A)\n",
    "\n",
    "                curr_summand = Di * np.log(2 * np.pi) + slogdet(A)[1] + np.trace(A_inv @ np.outer(x, x))\n",
    "                running_sum_X += curr_summand\n",
    "\n",
    "            running_sum_Y = 0\n",
    "            for ii in range(m):\n",
    "                M = Ms[ii]\n",
    "                B = Bs[ii]\n",
    "                y = M @ np.nan_to_num(Y[:, ii], nan=0)\n",
    "                Ei = M.shape[0]\n",
    "                B_inv = inv(B)\n",
    "\n",
    "                curr_summand = Ei * np.log(2 * np.pi) + slogdet(B)[1] + np.trace(B_inv @ np.outer(y, y))\n",
    "                running_sum_Y += curr_summand\n",
    "\n",
    "            LL = -0.5 * running_sum_X + gamma/2.0 * running_sum_Y\n",
    "\n",
    "            return LL\n",
    "\n",
    "        X_col_means = np.nanmean(X.T, axis=0)\n",
    "        Y_col_means = np.nanmean(Y.T, axis=0)\n",
    "\n",
    "        # Find indices that you need to replace\n",
    "        inds_X = np.where(np.isnan(X.T))\n",
    "        inds_Y = np.where(np.isnan(Y.T))\n",
    "\n",
    "        # Place column means in the indices. Align the arrays using take\n",
    "        X_copy, Y_copy = X.copy(), Y.copy()\n",
    "        X_copy, Y_copy = X_copy.T, Y_copy.T\n",
    "        X_copy[inds_X] = np.take(X_col_means, inds_X[1])\n",
    "        Y_copy[inds_Y] = np.take(Y_col_means, inds_Y[1])\n",
    "        X_copy -= X_copy.mean(0)\n",
    "        Y_copy -= Y_copy.mean(0)\n",
    "        X_copy, Y_copy = X_copy.T, Y_copy.T\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        pcpca_init = PCPCA(gamma=self.gamma, n_components=self.k)\n",
    "        pcpca_init.fit(X_copy, Y_copy)\n",
    "        W, sigma2 = pcpca_init.W_mle, 2  # pcpca_init.sigma2_mle\n",
    "\n",
    "        # Adam\n",
    "        alpha = 0.01\n",
    "        beta_1 = 0.9\n",
    "        beta_2 = 0.999  # initialize the values of the parameters\n",
    "        epsilon = 1e-8\n",
    "        m_t = 0\n",
    "        v_t = 0\n",
    "        m_t_sigma2 = 0\n",
    "        v_t_sigma2 = 0\n",
    "        t = 0\n",
    "        # W = np.random.normal(size=(X.shape[0], self.k))\n",
    "        # sigma2 = 3.0\n",
    "\n",
    "        ll_trace = []\n",
    "        ll_last = 0\n",
    "        for iter_num in range(n_iter):  # till it gets converged\n",
    "            t += 1\n",
    "            # computes the gradient of the stochastic function\n",
    "            g_t_W, g_t_sigma2 = grads(X, Y, W, sigma2, self.gamma)\n",
    "\n",
    "            # W\n",
    "            # updates the moving averages of the gradient\n",
    "            m_t = beta_1*m_t + (1-beta_1)*g_t_W\n",
    "            # updates the moving averages of the squared gradient\n",
    "            v_t = beta_2*v_t + (1-beta_2)*(g_t_W*g_t_W)\n",
    "            # calculates the bias-corrected estimates\n",
    "            m_cap = m_t/(1-(beta_1**t))\n",
    "            # calculates the bias-corrected estimates\n",
    "            v_cap = v_t/(1-(beta_2**t))\n",
    "            W_prev = W\n",
    "            # updates the parameters\n",
    "            W = W + (alpha*m_cap)/(np.sqrt(v_cap)+epsilon)\n",
    "\n",
    "            # sigma2\n",
    "            # updates the moving averages of the gradient\n",
    "            m_t_sigma2 = beta_1*m_t_sigma2 + (1-beta_1)*g_t_sigma2\n",
    "            # updates the moving averages of the squared gradient\n",
    "            v_t_sigma2 = beta_2*v_t_sigma2 + (1-beta_2)*(g_t_sigma2*g_t_sigma2)\n",
    "            # calculates the bias-corrected estimates\n",
    "            m_cap = m_t_sigma2/(1-(beta_1**t))\n",
    "            # calculates the bias-corrected estimates\n",
    "            v_cap = v_t_sigma2/(1-(beta_2**t))\n",
    "            sigma2_prev = sigma2\n",
    "            # updates the parameters\n",
    "            sigma2 = sigma2 + (alpha*m_cap)/(np.sqrt(v_cap)+epsilon)\n",
    "\n",
    "            # Threshold\n",
    "            sigma2 = max(sigma2, 1e-4)\n",
    "\n",
    "            if verbose and (iter_num % 20) == 0:\n",
    "                ll = log_likelihood(X, Y, W, sigma2, self.gamma)\n",
    "                if np.abs(ll - ll_last) < 0.1:\n",
    "                    break\n",
    "                ll_last = ll\n",
    "                print(\"Iter: {} \\t LL: {}\".format(iter_num, round(ll, 2)))\n",
    "\n",
    "        self.sigma2_mle = sigma2\n",
    "        self.W_mle = W\n",
    "        return W, sigma2\n",
    "\n",
    "    def _create_permuation_matrix(self, idx):\n",
    "\n",
    "        P = np.zeros((idx.shape[0], idx.shape[0]))\n",
    "        for ii, curr_idx in enumerate(idx):\n",
    "            P[ii, curr_idx] = 1\n",
    "        return P\n",
    "\n",
    "    def _compute_Exxi(self, x, A):\n",
    "\n",
    "        # Arrange data into observed and unobserved\n",
    "        observed_idx = np.where(~np.isnan(x))[0]\n",
    "        unobserved_idx = np.setdiff1d(np.arange(self.p), observed_idx)\n",
    "        n_observed, n_unobserved = len(observed_idx), len(unobserved_idx)\n",
    "        xo = x[observed_idx]\n",
    "        xu = x[unobserved_idx]\n",
    "\n",
    "        # Put A into block matrix form\n",
    "        A_sorted_idx = np.concatenate([observed_idx, unobserved_idx])\n",
    "        A = A[A_sorted_idx, :][:, A_sorted_idx]\n",
    "\n",
    "        # Pull out blocks\n",
    "        Aoo = A[:n_observed, :n_observed]\n",
    "        Auo = A[n_observed:, :n_observed]\n",
    "        Aou = Auo.T\n",
    "        Auu = A[n_observed:, n_observed:]\n",
    "\n",
    "        # Compute Mi/Mj\n",
    "        Aoo_inv = np.linalg.inv(Aoo)\n",
    "        Ai_lowerright = Auu - Auo @ Aoo_inv @ Aou\n",
    "        Ai = np.block([\n",
    "            [np.zeros((n_observed, n_observed)),\n",
    "             np.zeros((n_observed, n_unobserved))],\n",
    "            [np.zeros((n_unobserved, n_observed)),    Ai_lowerright]])\n",
    "\n",
    "        # Compute mui/muj\n",
    "        mui = np.concatenate([xo, Auo @ Aoo_inv @ xo])\n",
    "\n",
    "        # Compute expectation of outer product\n",
    "        Exxi = Ai + np.outer(mui, mui)\n",
    "\n",
    "        # Permute back to original indices\n",
    "        P = self._create_permuation_matrix(A_sorted_idx)\n",
    "        Exxi = P @ Exxi @ P\n",
    "\n",
    "        return Exxi\n",
    "\n",
    "    def _compute_Co(self, X, Y, A):\n",
    "\n",
    "        Exxis = np.zeros((self.p, self.p))\n",
    "        for ii in range(self.n):\n",
    "            Exxi = self._compute_Exxi(X[:, ii], A)\n",
    "            Exxis += Exxi\n",
    "\n",
    "        Eyyjs = np.zeros((self.p, self.p))\n",
    "        for jj in range(self.m):\n",
    "            Eyyj = self._compute_Exxi(Y[:, jj], A)\n",
    "            Eyyjs += Eyyj\n",
    "\n",
    "        Co = Exxis - self.gamma * Eyyjs\n",
    "        return Co\n",
    "\n",
    "    def _log_likelihood(self, X, W, sigma2):\n",
    "        p = X.shape[0]\n",
    "        return np.sum(multivariate_normal.logpdf(X.T, mean=np.zeros(p), cov=W @ W.T + sigma2 * np.eye(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreground_a shape:  (13, 35)\n",
      "Foreground_b shape:  (1695, 35)\n",
      "Background shape:  (25170, 35)\n",
      "Foreground shape:  (1708, 35)\n"
     ]
    }
   ],
   "source": [
    "# What if we instead used state representations?\n",
    "# Y = one of the features\n",
    "\n",
    "m = 200\n",
    "data = pd.read_csv(\"covid_12h.csv\")\n",
    "data = data.dropna()\n",
    "columns = ['ALBUMIN', 'ANION GAP',\n",
    "       'BASE EXCESS', 'BICARBONATE', 'BILIRUBIN', 'CALCIUM',\n",
    "       'CARBOXYHEMOGLOBIN', 'CHLORIDE', 'CREATININE', 'HEMATOCRIT',\n",
    "       'HEMOGLOBIN', 'INSPIRED OXYGEN', 'INTERNATIONAL NORMALIZED RATIO',\n",
    "       'LACTATE', 'METHEMOGLOBIN', 'PARTIAL THROMBOPLASTIN TIME', 'PCO2', 'PH',\n",
    "       'PLATELETS', 'PO2', 'POTASSIUM', 'SODIUM', 'UREA NITROGEN',\n",
    "       'URINE OUTPUT', 'WHITE BLOOD CELLS', 'FIO2', 'PEEP', 'OXYGEN (L)',\n",
    "       'Respiratory Aids', 'Nonsteroidal Anti-inflammatory Agents (NSAIDs)',\n",
    "       'Corticosteroids - Topical', 'Mineralocorticoids',\n",
    "       'Glucocorticosteroids', 'Influenza Agents', 'Antiretrovirals']\n",
    "\n",
    "\n",
    "background = data[data['Glucocorticosteroids'] == 0][columns].to_numpy()\n",
    "foreground = data[data['Glucocorticosteroids'] == 1]\n",
    "foreground_a = foreground[foreground['is_deceased_next_t'] == 1][columns].to_numpy()\n",
    "foreground_b = foreground[foreground['is_deceased_next_t'] == 0][columns].to_numpy()\n",
    "\n",
    "\n",
    "print(\"Foreground_a shape: \", foreground_a.shape)\n",
    "print(\"Foreground_b shape: \", foreground_b.shape)\n",
    "\n",
    "print(\"Background shape: \", background.shape)\n",
    "foreground = np.concatenate([foreground_a, foreground_b], axis=0)\n",
    "print(\"Foreground shape: \", foreground.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0 MSE: 230733132980.9332\n",
      "Gamma: 1 MSE: 344110813244.2098\n",
      "Gamma: 10 MSE: 359164367385.34656\n",
      "Gamma: 40 MSE: 360335691294.86395\n",
      "Gamma: 50 MSE: 360413355062.82446\n",
      "Gamma: 100 MSE: 360568524386.8372\n",
      "Gamma: 200 MSE: 360646030050.2864\n",
      "Gamma: 250 MSE: 360661524869.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4032x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = foreground\n",
    "Y = background\n",
    "X, Y = X.T, Y.T\n",
    "\n",
    "gamma_range = [0, 1, 10, 40, 50, 100, 200, 250]\n",
    "k = 1\n",
    "plt.figure(figsize=(len(gamma_range) * 7, 5))\n",
    "for ii, gamma in enumerate(gamma_range):\n",
    "    pcpca = PCPCA(gamma=gamma, n_components=k)\n",
    "    pcpca.fit(X, Y)\n",
    "\n",
    "#     plt.subplot(1, len(gamma_range), ii+1)\n",
    "#     if gamma == 0:\n",
    "#         plt.title(r'$\\gamma^\\prime$={}  (PPCA)'.format(gamma))\n",
    "#     else:\n",
    "#         plt.title(r'$\\gamma^\\prime$={}'.format(gamma))\n",
    "#     plt.scatter(X[0, :283], X[1, :283], alpha=0.5, label=\"INR == -1\", s=80, color=\"green\")\n",
    "#     plt.scatter(X[0, 283:], X[1, 283:], alpha=0.5, label=\"INR > -1\", s=80, color=\"orange\")\n",
    "#     plt.scatter(Y[0, :], Y[1, :], alpha=0.5, label=\"Background\", s=80, color=\"gray\")\n",
    "#     plt.legend()\n",
    "#     plt.xlim([-7, 7])\n",
    "#     plt.ylim([-7, 7])\n",
    "\n",
    "#     origin = np.array([[0], [0]])  # origin point\n",
    "#     # This is the line that distinguishes between the two classes.\n",
    "#     abline(slope=pcpca.W_mle[1, 0] / pcpca.W_mle[0, 0], intercept=0)\n",
    "    \n",
    "    #print(\"W shape: \", pcpca.W_mle)\n",
    "    print(\"Gamma: \" + str(gamma) + \" MSE: \" + str(pcpca.sigma2_mle))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#import ipdb\n",
    "#ipdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
